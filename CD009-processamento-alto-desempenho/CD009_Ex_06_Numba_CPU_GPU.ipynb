{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1i1vzSpHD8InOahvgFV4hI7yaNr_9RlXB","timestamp":1668635464281}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Ex06 - Numba CPU/GPU"],"metadata":{"id":"IixZxZwq-Ctq"}},{"cell_type":"markdown","source":["O objetivo deste exercício é averiguar os ganhos de desempenho do emprego de Numba.\n","- Parte 1: ver o efeito da compilação JIT (*just-in-time*), \n","- Parte 2: ver o efeito da compilação para código a ser executado na GPU\n","  - Utilize um *runtime* GPU\n","\n","---\n","\n"],"metadata":{"id":"iNfUhUsx-akv"}},{"cell_type":"code","source":["!pip install numba"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kxtzvtKvL_Lu","executionInfo":{"status":"ok","timestamp":1668715862697,"user_tz":180,"elapsed":2812,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"outputId":"44b9a745-0427-4955-ad0d-d63b4245ad47"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (0.56.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba) (57.4.0)\n","Requirement already satisfied: numpy<1.24,>=1.18 in /usr/local/lib/python3.7/dist-packages (from numba) (1.21.6)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba) (0.39.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba) (4.13.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba) (3.10.0)\n"]}]},{"cell_type":"markdown","source":["## Parte 1 - JIT para CPU"],"metadata":{"id":"G81vTyy7-nTU"}},{"cell_type":"markdown","source":["O código abaixo implementa o cálculo aproximado do número de pi através do método de monte-carlo. Para uma quantidade `n` de vezes, a função gera dois números pseudoaleatórios entre 0 e 1 com `uniform` que representam uma coordenada no espaço cartesiano compreendido entre 0 e 1 tanto no eixo x quanto no eixo y, calcula a distância `d`. Caso esta distância for menor que 0.5, significa que a coordenada aleatória está dentro do círculo. A área estimada `area_estimate` é calculada como a razão entre a quantidade de vezes que a coordenada foi considerada dentro do círculo em relação a quantidade total de pontos gerados."],"metadata":{"id":"ohybxioZ-sM1"}},{"cell_type":"code","source":["import numpy as np\n","from random import uniform\n","\n","def calculate_pi(n=1_000_000):\n","    count = 0\n","    for i in range(n):\n","        u, v = uniform(0, 1), uniform(0, 1)\n","        d = np.sqrt((u - 0.5)**2 + (v - 0.5)**2)\n","        if d < 0.5:\n","            count += 1\n","\n","    area_estimate = count / n\n","    return area_estimate * 4  # dividing by radius**2"],"metadata":{"id":"EqwivO2x70f5","executionInfo":{"status":"ok","timestamp":1668715862698,"user_tz":180,"elapsed":6,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}}},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":["Este código, quando executado com o valor de `n` padrão, obtemos o seguinte tempo de execução."],"metadata":{"id":"tiWLOSFC_o36"}},{"cell_type":"code","source":["%timeit calculate_pi()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IFTOU-X-_mWI","executionInfo":{"status":"ok","timestamp":1668715879495,"user_tz":180,"elapsed":16802,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"outputId":"972d78be-b43c-415d-d966-730930d6d029"},"execution_count":115,"outputs":[{"output_type":"stream","name":"stdout","text":["2.13 s ± 829 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"]}]},{"cell_type":"markdown","source":["### **(Tarefa)** Empregue o decorador `@jit` para acelerar `calculate_pi`"],"metadata":{"id":"f2TYU-6dAVwI"}},{"cell_type":"code","source":["import numba\n","from numba import jit\n","@jit(nopython=True)\n","def calculate_pi_jit(n=1_000_000):\n","    count = 0\n","    for i in range(n):\n","        u, v = uniform(0, 1), uniform(0, 1)\n","        d = np.sqrt((u - 0.5)**2 + (v - 0.5)**2)\n","        if d < 0.5:\n","            count += 1\n","\n","    area_estimate = count / n\n","    return area_estimate * 4  # dividing by radius**2"],"metadata":{"id":"HzSFChbLBBST","executionInfo":{"status":"ok","timestamp":1668715879496,"user_tz":180,"elapsed":5,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}}},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":["Para fins de exemplo, abaixo a medição de tempo obtida pelo professor (substitua pela sua implementação)."],"metadata":{"id":"MEqNyGaeP5D0"}},{"cell_type":"code","source":["%timeit calculate_pi_jit()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3nOeHWHYAxIo","executionInfo":{"status":"ok","timestamp":1668715895820,"user_tz":180,"elapsed":16329,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"outputId":"1cef9a48-a8b1-4f8b-d485-d21f9a875340"},"execution_count":117,"outputs":[{"output_type":"stream","name":"stdout","text":["20.6 ms ± 6.02 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"]}]},{"cell_type":"markdown","source":["## Parte 2 - JIT para GPU"],"metadata":{"id":"dDSP8cpOBERf"}},{"cell_type":"markdown","source":["Para este exercício, vamos abordar o funcionamento de reduções com Numba CUDA e como gerar números aleatórios na GPU."],"metadata":{"id":"1Tgj12zjBJaJ"}},{"cell_type":"markdown","source":["### Redução em GPU"],"metadata":{"id":"u3vERUnKJO6x"}},{"cell_type":"markdown","source":["Para tal, primeiro vemos a redução de um vetor para um único valor, por exemplo, utilizando `np.sum`."],"metadata":{"id":"MhwxRQYkJFUP"}},{"cell_type":"code","source":["import numpy as np\n","v = np.arange(1,1_000_000)\n","np.sum(v)"],"metadata":{"id":"xP004yEvBWKs","executionInfo":{"status":"ok","timestamp":1668715895820,"user_tz":180,"elapsed":4,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c35d36e-1fc5-4be5-d6cf-62888c0c73bf"},"execution_count":118,"outputs":[{"output_type":"execute_result","data":{"text/plain":["499999500000"]},"metadata":{},"execution_count":118}]},{"cell_type":"markdown","source":["Para fazer o mesmo em GPU, precisamos utilizar o decorador `@cuda.reduce` em uma função de aridade dupla (com dois argumentos), assim:"],"metadata":{"id":"rOAIph2yBkg7"}},{"cell_type":"code","execution_count":119,"metadata":{"id":"GrMG0w1L4okM","executionInfo":{"status":"ok","timestamp":1668715895820,"user_tz":180,"elapsed":3,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}}},"outputs":[],"source":["from numba import cuda\n","@cuda.reduce\n","def sum_reduce(a, b):\n","    return a + b"]},{"cell_type":"markdown","source":["Vamos agora testá-la:\n","1. Gerar um vetor `v` de elementos\n","2. Copiar os dados para o device, com `cuda.to_device()`\n","3. Invocar o kernel com a referência dos dados já no device."],"metadata":{"id":"8N2_iQq0CHW3"}},{"cell_type":"code","source":["v = np.arange(1, 1_000_000)   #1\n","dev_v = cuda.to_device(v)     #2\n","sum_reduce(dev_v)             #3"],"metadata":{"id":"28QU4HhFCF3b","executionInfo":{"status":"ok","timestamp":1668715896337,"user_tz":180,"elapsed":520,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"62a6cc2c-2411-4e5d-a890-eb5be1a3367a"},"execution_count":120,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 64 will likely result in GPU under-utilization due to low occupancy.\n","  warn(NumbaPerformanceWarning(msg))\n","/usr/local/lib/python3.7/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n","  warn(NumbaPerformanceWarning(msg))\n"]},{"output_type":"execute_result","data":{"text/plain":["499999500000"]},"metadata":{},"execution_count":120}]},{"cell_type":"markdown","source":["### Geração de números aleatórios em GPU"],"metadata":{"id":"Z-PfF1b9JVwZ"}},{"cell_type":"markdown","source":["Ao empregar a geração de números aleatórios na GPU, é importante garantir que cada CUDA thread tenha o seu próprio estado, de uma maneira que cada CUDA thread gere sequências independentes, sem intersecção. O módulo `numba.cuda.random` fornece toda a funcionalidade para colocar isso em prática, inclusive para gerar números uniformemente distribuídos (necessário para o cálculo de pi). Vamos revisar esses elementos agora."],"metadata":{"id":"_8XWlj8GJZ7_"}},{"cell_type":"markdown","source":["Primeiro, vamos importar as funções que importam. A função `create_xoroshiro128p_states` gera um arranjo de estados independentes a serem utilizados no device, enquanto que `xoroshiro128p_uniform_float32` gera números uniformemente distribuídos em um intervalo, e recebe como entrada o arranjo de estados. Esta deve ser chamada no código executado no device."],"metadata":{"id":"7Y43qYRSJ-ei"}},{"cell_type":"code","source":["from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32"],"metadata":{"id":"WRY1qkFoKHbv","executionInfo":{"status":"ok","timestamp":1668715896337,"user_tz":180,"elapsed":7,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}}},"execution_count":121,"outputs":[]},{"cell_type":"markdown","source":["Vamos criar na memória do device um arranjo com os estados independentes. Neste exemplo, estamos criando 128 estados. Em uso prático, deve haver um estado para cada CUDA thread que será lançada."],"metadata":{"id":"ZjNv9MR5KnHx"}},{"cell_type":"code","source":["quantidade_de_estados = 128\n","estados = create_xoroshiro128p_states (quantidade_de_estados, seed = 1)\n","estados"],"metadata":{"id":"Iu0JpUApKiRP","executionInfo":{"status":"ok","timestamp":1668715896337,"user_tz":180,"elapsed":6,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"66743c22-cec1-4972-ccba-a88812ee2efd"},"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<numba.cuda.cudadrv.devicearray.DeviceNDArray at 0x7f1d51117110>"]},"metadata":{},"execution_count":122}]},{"cell_type":"markdown","source":["A função `xoroshiro128p_uniform_float32`, chamada no código executado no device, retorna um número no intervalo [0, 1). Ela recebe os estados o identificador única da CUDA thread que está a invocando."],"metadata":{"id":"6ECxBRp0Ldbk"}},{"cell_type":"markdown","source":["A função abaixo `gera_numeros_aleatorios_na_GPU` é um gerador paralelo de números aleatórios usando Numba em GPU."],"metadata":{"id":"f2psD9BFLpz_"}},{"cell_type":"code","source":["from numba import cuda\n","@cuda.jit\n","def gera_numeros_aleatorios_na_GPU(estados, out):\n","    tid = cuda.grid(1) # identificador único da thread\n","    x = xoroshiro128p_uniform_float32(estados, tid)\n","    out[tid] = x"],"metadata":{"id":"v_ecVX30Lt9O","executionInfo":{"status":"ok","timestamp":1668715896338,"user_tz":180,"elapsed":4,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}}},"execution_count":123,"outputs":[]},{"cell_type":"markdown","source":["Vamos gerar `N` números aleatórios, em blocos com 64 threads."],"metadata":{"id":"P710HTknMxXE"}},{"cell_type":"code","source":["N = 128*1000                      # garantir que N é múltipl de 64\n","threads_per_block = 64\n","blocks = int(N/threads_per_block) # deve ser um número inteiro"],"metadata":{"id":"4goKYmG2Mu3a","executionInfo":{"status":"ok","timestamp":1668715896338,"user_tz":180,"elapsed":4,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}}},"execution_count":124,"outputs":[]},{"cell_type":"markdown","source":["Criar os estados."],"metadata":{"id":"xc_sbZ53NAeZ"}},{"cell_type":"code","source":["estados = create_xoroshiro128p_states(N, seed=1)"],"metadata":{"id":"w0DkUc8FM_-5","executionInfo":{"status":"ok","timestamp":1668715896339,"user_tz":180,"elapsed":5,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}}},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":["Agora, preparar a variável de saída `out`, copiá-la para a GPU com `to_device`, invocar o kernel e repatriar os dados para a RAM."],"metadata":{"id":"XWA59PZ4NFWw"}},{"cell_type":"code","source":["import numpy as np\n","out = np.zeros(N, dtype=np.float32)\n","out_dev = cuda.to_device(out)\n","gera_numeros_aleatorios_na_GPU[blocks, threads_per_block](estados, out_dev)\n","saida = out_dev.copy_to_host()\n","saida"],"metadata":{"id":"m2n-w98wNE9C","executionInfo":{"status":"ok","timestamp":1668715896726,"user_tz":180,"elapsed":391,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3e9ae895-7c47-40e5-edd7-87bf3a028520"},"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.13312314, 0.87634873, 0.8710909 , ..., 0.2169639 , 0.49467936,\n","       0.19529185], dtype=float32)"]},"metadata":{},"execution_count":126}]},{"cell_type":"markdown","source":["Agora vamos à tarefa."],"metadata":{"id":"laED9OvYIaSh"}},{"cell_type":"code","source":["saida.size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZdALoH4LQP9","executionInfo":{"status":"ok","timestamp":1668715896726,"user_tz":180,"elapsed":6,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"outputId":"1deb20e0-860f-4f48-817c-6df01ca0ae82"},"execution_count":127,"outputs":[{"output_type":"execute_result","data":{"text/plain":["128000"]},"metadata":{},"execution_count":127}]},{"cell_type":"markdown","source":["### **(Tarefa)** Empregue o decorador `@cuda.jit` para acelerar `calculate_pi`"],"metadata":{"id":"xy73ehxrINIF"}},{"cell_type":"markdown","source":["O objetivo desta tarefa é realizar o cálculo de pi na GPU, empregando o decorador `@cuda.jit`."],"metadata":{"id":"0rC06bEpIbyL"}},{"cell_type":"markdown","source":["Para realizar esta tarefa, uma estratégia possível é fazer com que cada thread gere coordenadas de maneira aleatória (uma ou mais vezes), verificando se cada coordenada gerada faz parte do círculo unitário e contabilizando aquelas que fazem parte. Como cada thread sabe quantas coordenadas foram geradas, ela consegue calcular sua aproximação local para o valor de pi (da mesma forma que o código disponibilizado no início deste caderno de anotações). No final, os resultados destas aproximações estarão em arranjo na memória da GPU. Para terminar, podes acumular estas aproximações fazendo um processo de redução na GPU."],"metadata":{"id":"cYMIK0DGIimx"}},{"cell_type":"code","source":["from numba import cuda\n","import numpy as np\n","import math\n","\n","@cuda.jit\n","def gera_coordenadas_GPU(estados, out):       \n","    tid = cuda.grid(1) # identificador único da thread\n","    u = xoroshiro128p_uniform_float32(estados, tid)\n","    v = xoroshiro128p_uniform_float32(estados, tid)    \n","    d = math.sqrt((u - 0.5)**2 + (v - 0.5)**2)\n","    if d < 0.5:   \n","      out[tid] = 1\n","    else:\n","      out[tid] = 0  \n","\n"],"metadata":{"id":"ux9-olrLH_BV","executionInfo":{"status":"ok","timestamp":1668715896727,"user_tz":180,"elapsed":5,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}}},"execution_count":128,"outputs":[]},{"cell_type":"code","source":["\n","import numpy as np\n","\n","def calculate_pi_jitcuda():  \n","  estados = create_xoroshiro128p_states(N, seed=1)\n","  out = np.zeros(N, dtype=np.float32)\n","  out_dev = cuda.to_device(out)\n","  gera_coordenadas_GPU[blocks, threads_per_block](estados, out_dev)\n","  saida = out_dev.copy_to_host()\n","  saida\n","  # saida.size\n","\n","  # Somatório e cálculo final\n","  dev_v = cuda.to_device(saida)\n","  area_estimate = sum_reduce(dev_v) / saida.size\n","  area_estimate\n","  area_estimate * 4"],"metadata":{"id":"RjQu0hWYL3rf","executionInfo":{"status":"ok","timestamp":1668715896727,"user_tz":180,"elapsed":5,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}}},"execution_count":129,"outputs":[]},{"cell_type":"code","source":["%timeit calculate_pi_jitcuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"seLLw-BYGzzs","executionInfo":{"status":"ok","timestamp":1668715897720,"user_tz":180,"elapsed":998,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"outputId":"2ac52ca8-f2e9-448b-ef43-80ebc8c28a71"},"execution_count":130,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 64 will likely result in GPU under-utilization due to low occupancy.\n","  warn(NumbaPerformanceWarning(msg))\n","/usr/local/lib/python3.7/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n","  warn(NumbaPerformanceWarning(msg))\n"]},{"output_type":"stream","name":"stdout","text":["35 ms ± 1.92 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"]}]},{"cell_type":"markdown","source":["## Questionamentos finais"],"metadata":{"id":"KJfcLCpxOoGJ"}},{"cell_type":"markdown","source":["1. A versão em GPU ficou mais rápida que o código (com ou sem JIT) CPU observado acima?\n"],"metadata":{"id":"I0e2cfC6Ok6L"}},{"cell_type":"markdown","source":["Resultados\n","Código comum:\n","\n","2.1 s ± 864 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Código JIT:\n","\n","14.9 ms ± 2.61 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","\n","Código JIT CUDA:\n","\n","27.5 ns ± 0.36 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n","\n","Sim. O resultado com GPU foi muito superior."],"metadata":{"id":"U3MqFJW_HFWm"}},{"cell_type":"markdown","source":["2. Na versão GPU, observa-se alguma diferença de desempenho entre a quantidade de threads por bloco?"],"metadata":{"id":"HjHJitBNHBNm"}},{"cell_type":"markdown","source":["Testamos com valores de blocos variados: 16, 32, 128, 256, 512.\n","\n","Não encontramos variação significativa."],"metadata":{"id":"8KzotJmEOJcn"}},{"cell_type":"code","source":["N = 128*1000                      # garantir que N é múltipl de 64\n","threads_per_block = 64\n","blocks = int(N/threads_per_block) # deve ser um número inteiro\n","\n","%timeit calculate_pi_jitcuda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g2vsrHDZM-7B","executionInfo":{"status":"ok","timestamp":1668715900240,"user_tz":180,"elapsed":2522,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"outputId":"c7257caa-954a-444f-facb-92b105ffa247"},"execution_count":131,"outputs":[{"output_type":"stream","name":"stdout","text":["32.7 ns ± 10.7 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"]}]},{"cell_type":"code","source":["N = 128*1000                      # garantir que N é múltipl de 64\n","threads_per_block = 32\n","blocks = int(N/threads_per_block) # deve ser um número inteiro\n","\n","%timeit calculate_pi_jitcuda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2p8T3LcfNHBp","executionInfo":{"status":"ok","timestamp":1668715902390,"user_tz":180,"elapsed":2154,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"outputId":"adce92a7-d197-435f-e99a-96484f78e18b"},"execution_count":132,"outputs":[{"output_type":"stream","name":"stdout","text":["27.7 ns ± 5.95 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"]}]},{"cell_type":"code","source":["N = 128*1000                      # garantir que N é múltipl de 64\n","threads_per_block = 16\n","blocks = int(N/threads_per_block) # deve ser um número inteiro\n","\n","%timeit calculate_pi_jitcuda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mfzwRGDSNJfV","executionInfo":{"status":"ok","timestamp":1668715905002,"user_tz":180,"elapsed":2615,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"outputId":"1bfd8a51-e519-4573-a72f-0b9a1ab779f6"},"execution_count":133,"outputs":[{"output_type":"stream","name":"stdout","text":["34.2 ns ± 7.43 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"]}]},{"cell_type":"code","source":["N = 128*1000                      # garantir que N é múltipl de 64\n","threads_per_block = 128\n","blocks = int(N/threads_per_block) # deve ser um número inteiro\n","\n","%timeit calculate_pi_jitcuda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2n0Rp3PGNMRb","executionInfo":{"status":"ok","timestamp":1668715907204,"user_tz":180,"elapsed":2205,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"outputId":"3b572566-d159-4201-cb1c-64a3f1c857f5"},"execution_count":134,"outputs":[{"output_type":"stream","name":"stdout","text":["24.7 ns ± 0.383 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"]}]},{"cell_type":"code","source":["N = 128*1000                      # garantir que N é múltipl de 64\n","threads_per_block = 256\n","blocks = int(N/threads_per_block) # deve ser um número inteiro\n","\n","%timeit calculate_pi_jitcuda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MNSqQiTgNQIK","executionInfo":{"status":"ok","timestamp":1668715909084,"user_tz":180,"elapsed":1883,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"outputId":"ebcb03e7-48a9-4e58-ea8c-6fb426b1703d"},"execution_count":135,"outputs":[{"output_type":"stream","name":"stdout","text":["24.7 ns ± 0.419 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"]}]},{"cell_type":"code","source":["N = 128*1000                      # garantir que N é múltipl de 64\n","threads_per_block = 512\n","blocks = int(N/threads_per_block) # deve ser um número inteiro\n","\n","%timeit calculate_pi_jitcuda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FZSeQzOMN-L1","executionInfo":{"status":"ok","timestamp":1668715931880,"user_tz":180,"elapsed":2167,"user":{"displayName":"Hua Lin Chang","userId":"03959591815833402629"}},"outputId":"c838dc33-b66f-47dd-9c65-a4359088ce1c"},"execution_count":144,"outputs":[{"output_type":"stream","name":"stdout","text":["24.4 ns ± 0.501 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"]}]}]}