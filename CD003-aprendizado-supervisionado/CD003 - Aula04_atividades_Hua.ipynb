{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CD003 - Aula04_atividades_Hua.ipynb","provenance":[{"file_id":"1UXTVxJDUeDHbsbDLxqc3KWf_nSU-7Tn1","timestamp":1652786557060}],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Especialização em Ciência de Dados - INF/UFRGS e SERPRO**\n","### Disciplina CD003 - Aprendizado Supervisionado\n","#### *Profa. Mariana Recamonde-Mendoza (mrmendoza@inf.ufrgs.br)*\n","<br> \n","\n","---\n","***Observação:*** *Este notebook é disponibilizado aos alunos como complemento às aulas síncronas e aos slides preparados pela professora. Desta forma, os principais conceitos são apresentados no material teórico fornecido. O objetivo deste notebook é reforçar os conceitos e demonstrar questões práticas no uso de diferentes algoritmos e estratégias de Aprendizado de Máquina.*\n","\n","\n","---\n"],"metadata":{"id":"0FA12O8Tpjmk"}},{"cell_type":"markdown","source":["<br>\n","\n","## **Aula 04** - **Tópico: Máquinas de Vetores de Suporte**\n","\n","<br>\n","\n","O algoritmo **Máquinas de Vetores de Suporte**, conhecido por **SVM** (de *Support Vector Machines*, em inglês), é amplamente utilizado para tarefas de classificação e regressão, possuindo uma grande versatilidade e alto poder de modelagem para problemas lineares e não-lineares.\n","\n","Conforme discutido em aula, o algoritmo encontra a fronteira de decisão formulando a tarefa de aprendizado como um problema de otimização. O SVM localiza a reta ou hiperplano que separa as instâncias de treinamento em duas regiões de forma a maximizar a margem entre os vetores de suporte das duas classes analisadas. Para problemas multiclasse, a tarefa de classificação é decomposta em um conjunto de problemas de classificação binária.\n","\n","A versatilidade do SVM vem do uso de diferentes tipos de kernel, que são funções que realizam transformações nos dados a fim de projetá-los em um espaço de dimensão superior, de forma a permitir que relações não-lineares sejam modeladas com um classificador linear. Além do kernel linear, outros tipos de kernel muito utilizados são o Polinomial e o Radial Basis Function (RBF).\n","\n","<br> \n","\n","**Objetivo deste notebook**: Exercitar o uso de SVM em tarefas de classificação, comparando diferentes tipos de kernel e realizando a otimização de hiperparâmetros do algoritmo.\n","\n","<br>\n","\n","---\n","\n"],"metadata":{"id":"EgsiZ2JI29zu"}},{"cell_type":"markdown","source":["##**Determinando a qualidade de vinhos verdes Portugueses**\n","\n","*Seria possível prever as preferências humanas sobre vinhos verdes (principalmente de provadores profissionais) a partir de testes analíticos que quantificam propriedades químicas dos vinhos?*\n","\n","Nesta atividade, vamos analisar um conjunto de observações sobre diversas amostras de vinho verde Português (do tipo branco), envolvendo suas propriedades químicas e classificação realizada por provadores através de análise sensorial. \n","\n","O preço do vinho depende de um conceito bastante abstrato de apreciação do vinho a partir de análise sensorial pelos provadores, cuja opinião pode ter um alto grau de variabilidade. Outro fator chave na certificação e avaliação da qualidade do vinho são os testes análiticos realizados em laboratório e facilmente disponíveis na etapa de certificação. Estes testes levam em consideração fatores como acidez, nível de pH, presença de açúcar e outras propriedades químicas. Para o setor vitivinícola, seria de interesse que a análise de qualidade humana no processo de degustação pudesse estar relacionada com as propriedades químicas do vinho aferidas com os testes analíticos. Assim,  o processo de avaliação e certificação da garantia da qualidade do vinho poderia ser mais controlado.\n","\n","\n","O conjunto de dados a ser analisado nesta atividade possui informações para 4898 amostras de vinhos verdes (tipo branco), todas produzidos em uma determinada zona de Portugal. Os atributos são coletados para 12 propriedades diferentes dos vinho: uma das quais é Qualidade, com base em análise sensorial por provadores, e as restantes são propriedades químicas dos vinhos, incluindo densidade, acidez, teor alcoólico, etc. Todas as propriedades químicas dos vinhos são variáveis ​​contínuas. A qualidade é uma variável ordinal com uma classificação possível de 1 (pior) a 10 (melhor). Cada variedade de vinho é provada por três provadores independentes e a classificação final atribuída é a classificação mediana dada pelos provadores.\n","\n","O conjunto de dados original foi publicado no artigo: *Cortez, P., Cerdeira, A., Almeida, F., Matos, T., & Reis, J. (2009). Modeling wine preferences by data mining from physicochemical properties. Decision support systems, 47(4), 547-553.*\n","\n","O objetivo desta tarefa é abordar a questão apontada no início desta seção, desenvolvendo um modelo capaz de predizer a classificação de um vinho com base nas suas propriedades químicas avaliadas em testes analíticos."],"metadata":{"id":"DbJNQfaM4ERT"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"jiutqCcGYYM0"}},{"cell_type":"markdown","source":["###Carregando e inspecionando os dados\n","\n","Primeiramente, vamos carregar algumas bibliotecas importantes do Python e os dados a serem utilizados neste estudo. Os dados são disponibilizados através de um link, que também pode ser diretamente acessado pelos alunos."],"metadata":{"id":"dbr-VwMq6OPG"}},{"cell_type":"code","source":["## Carregando as bibliotecas necessárias\n","%matplotlib inline              \n","import pandas as pd             # para análise de dados \n","import matplotlib.pyplot as plt # para visualização de informações\n","import seaborn as sns           # para visualização de informações\n","import numpy as np              # para operações com arrays multidimensionais\n","from sklearn.svm import SVC  ## para treinar um SVM\n","from sklearn.model_selection import train_test_split # para divisão de dados\n","from sklearn.metrics import confusion_matrix, recall_score, precision_score,accuracy_score,ConfusionMatrixDisplay ## para avaliação dos modelos\n","sns.set()"],"metadata":{"id":"2lyNg5Sluhbg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_table(\"https://drive.google.com/uc?export=view&id=11YsVJck74_gyADzGJSU9Uwn8cDq_l3BD\",sep=\";\")\n","df.head()  # para visualizar apenas as 5 primeiras linhas"],"metadata":{"id":"bPcnFsAB9kv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Características gerais do dataset\n","print(\"O conjunto de dados possui {} linhas e {} colunas\".format(df.shape[0], df.shape[1]))"],"metadata":{"id":"iCBVXyya-_tM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A coluna *'quality'* contém a classificação de qualidade de cada vinho, aferida pelos provadores. Vamos avaliar como as instâncias estão distribuídas entre os diferentes valores de *'quality'* presentes no dataset (originalmente os mesmos podem variar entre 0 e 10)."],"metadata":{"id":"UqoChZTpAEMu"}},{"cell_type":"code","source":["## Distribuição do atributo alvo, 'quality'\n","sns.countplot(x='quality', data=df)"],"metadata":{"id":"h0NT9TCiAeLX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Imprimindo o valor exato de número de instâncias por nota\n","print(df.groupby('quality').size())"],"metadata":{"id":"vMupLQ6yOGGa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Podemos perceber que todos os vinhos no conjunto de dados estão classificados com notas entre 3 e 9. Entretanto, poucos vinhos estão classificados nos extremos da distribuição (notas 3 e 9). "],"metadata":{"id":"kFZtoZCjOBCs"}},{"cell_type":"markdown","source":["Também é importante sempre confirmarmos os tipos de dados de cada atributo, bem como se existem valores faltantes. A célula seguinte faz esta inspeção."],"metadata":{"id":"9FfabKeQT8ja"}},{"cell_type":"code","source":["df.info()\n","\n","## Para analisar valores faltantes, quando codificados como NaN, podemos usar o\n","## comando abaixo\n","df.isnull().sum()"],"metadata":{"id":"yA30OBnnqPXf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vamos analisar a distribuição de valores para os atributos, os quais são todos numéricos como foi possível confirmar na célula de código anterior."],"metadata":{"id":"57_WB7PqW5_A"}},{"cell_type":"code","source":["## Criando vetor com nome dos atributos\n","features_names = df.columns.drop(['quality'])"],"metadata":{"id":"L2VyTmPuxkWB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Gerar um gráfico para cada variável numérica com a distribuição \n","## de frequência. Avaliar a distribuição geral ou, opcionalmente, \n","## a distribuição por classe (classificação do vinho) \n","\n","## Distribuição geral\n","def dist_plot(df,columns):\n","    plt.figure(figsize=(16, 10))\n","    for indx, var  in enumerate(columns):\n","        plt.subplot(4, 3, indx+1)\n","        g = sns.histplot(x=var, data=df)\n","    plt.tight_layout()\n","\n","## Distribuição por classe\n","def dist_plot_perclass(df,columns,label):\n","    plt.figure(figsize=(16, 10))\n","    for indx, var  in enumerate(columns):\n","        plt.subplot(4, 3, indx+1)\n","        sns.color_palette(\"pastel\")\n","        g = sns.histplot(x=var, data=df, hue=label,palette='muted')\n","    plt.tight_layout()\n","\n","\n","dist_plot(df, features_names)\n","dist_plot_perclass(df, features_names, 'quality')"],"metadata":{"id":"7QEWJ4FdEtxa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**>>> Responda:** Neste ponto já é possível avaliar a necessidade de normalização dos dados para treinamento do SVM. Analise o quanto os dados demandam pré-processamento para normalização dos valores."],"metadata":{"id":"SXoMj3hpDvil"}},{"cell_type":"markdown","source":["> ***Sua resposta aqui:*** Os atributos apresentam uma escala de valores muito diferentes. Por exemplo , o atributo \"total sulfur dioxide\" apresenta uma escala de valores muito alta. Enquanto os atributos \"volatile acidity\", \"citric acid\" e \"chlorides\", uma escala de valores muito baixa."],"metadata":{"id":"TBiPT880TLY6"}},{"cell_type":"markdown","source":["O gráfico abaixo mostra de outra forma como variam os valores dos atributos, considerando todas as instâncias no conjunto de dados.\n","\n","**>>> Responda:** Quais atributos possuem as escalas de valores mais discrepantes em relação ao conjunto total de atributos?"],"metadata":{"id":"NVoH2AFdErcu"}},{"cell_type":"markdown","source":["> ***Sua resposta aqui:*** Os atributos free \"sulfur dioxide\" e \"total sulfur dioxide\" apresentam as escalas de valores mais discrepantes."],"metadata":{"id":"JUq8N5ZCBmJ-"}},{"cell_type":"code","source":["df.drop(['quality'],axis=1).plot(figsize=(15,7))"],"metadata":{"id":"HqndUq5OP_QX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Por fim, para auxiliar no entendimento do problema, é interessante avaliar a correlação entre atributos, bem como a correlação dos atributos com a classificação da qualidade do vinho. Vamos criar um heatmap com a correlação de Pearson entre os atributos da base."],"metadata":{"id":"j_gTnhwoFKrs"}},{"cell_type":"code","source":["plt.figure(figsize=(12,10))\n","sns.heatmap(df.corr(), annot=True, cmap = 'coolwarm')\n","plt.show()"],"metadata":{"id":"uWwSliZoPNtC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["É possível visualizar o comportamente da correlação entre atributos e a classe através de lineplots. Visualize os dados para alguns atributos selecionados que apresentem correlação positiva ou negativa com quality (mesmo que a correlação seja fraca)."],"metadata":{"id":"899ouo7iGX0f"}},{"cell_type":"code","source":["feature_sel = \"alcohol\" #@param {type:\"string\"}\n","\n","plt.figure(figsize=(10,5))\n","sns.lineplot(data=df, x=\"quality\",y=feature_sel,color='r')"],"metadata":{"id":"B8ukjJrBF6KK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","\n","### Estruturando a tarefa de classificação: vinho bom ou medíocre?\n","\n","A análise exploratória dos dados nos mostrou que a qualidade dos vinhos no conjunto de dados disponível varia entre 3 e 9, com poucas instâncias sendo classificadas com as notas extremas. A distribuição dos dados sugere que a grande maioria dos vinhos possuem notas 5, 6 e 7. A falta de representatividade de vinhos com as demais classificações pode se apresentar como um problema para o desenvolvimento do modelo. \n","\n","**>>> Responda:** Qual possivelmente será o desempenho de um modelo treinado com estes dados para a classificação de novos vinhos com nota 9-10 ou nota 0-2?\n"," "],"metadata":{"id":"KHD3JpfDQ7Zj"}},{"cell_type":"markdown","source":["> ***Sua resposta aqui:*** O modelo não teria um bom desempenho, pois falta representatividade dessa classe na nossa amostra."],"metadata":{"id":"xlj9nNE6BoWo"}},{"cell_type":"markdown","source":["Para dar continuidade à modelagem do problema de classificação dos vinhos, vamos **investigar a possibilidade de distinguir bons vinhos de vinhos medíocres ou ruins**, utilizando **a nota de 7** como um ponto de corte. Vinhos com nota 7 ou superior serão classificados como bons vinhos (1), enquanto vinhos com notas 0-6 serão classificados como medíocres (0).\n"],"metadata":{"id":"WEsVyfIcBp44"}},{"cell_type":"code","source":["df['quality'] = df['quality'].replace([3, 4, 5, 6], 0)\n","df['quality'] = df['quality'].replace([7, 8, 9], 1)\n","sns.countplot(x='quality', data=df)"],"metadata":{"id":"wJ5ejYnGTUsR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","---\n","\n","\n","### Criando conjuntos de treino, validação e teste\n"," \n","Seguindo a mesma estratégia da aula passada, faremos a divisão dos dados em treino, validação e teste na proporção (sugerida) de 70%/15%/15% para fazer avaliação de desempenho dos modelos com um *holdout de 3 vias*. Na célula de código abaixo, os dados são inicialmente divididos entre duas variáveis: uma variável contendo os atributos e outra a classe a ser predita. Na sequência, implemente os seguintes passos:\n","\n","\n","1.   Utilize a fução train_test_split() para dividir os dados em treino, validação e teste. Caso tenha dúvidas, use como exemplo o código da aula 02.\n","2.   Normalize os dados usando o método MaxMin. Lembre-se que primeiramente os parâmetros de normalização são estimados a partir dos dados de treino e então aplicados a todos os três conjuntos.\n","\n"],"metadata":{"id":"63nQ-E0jVQzW"}},{"cell_type":"code","source":["## Separa o dataset em duas variáveis: os atributos/entradas (X) e a classe/saída (y)\n","X = df.drop(['quality'], axis=1)\n","y = df['quality'].values"],"metadata":{"id":"ABN2LAyMYIRb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Definindo as proporções de treino, validação e teste.\n","train_ratio = 0.70\n","test_ratio = 0.15\n","validation_ratio = 0.15\n","\n","\n","## Fazendo a primeira divisão, para separar um conjunto de teste dos demais.\n","## Assuma X_train e y_train para os dados de treinamento e X_test e y_test para os de teste\n","## Dica: configure o random_state para facilitar reprodutibilidade dos experimentos\n","\n","### \n","# Adicione aqui a sua resposta\n","##\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, stratify=y, random_state=42)\n","\n","## Fazendo a segunda divisão, para gerar o conjunto de treino e validação a partir \n","## do conjunto de 'treinamento' da divisão anterior\n","## Assuma X_train e y_train para os dados de treinamento e X_valid e y_valid para os de teste\n","## Dica: configure o random_state para facilitar reprodutibilidade dos experimentos\n","\n","### \n","# Adicione aqui a sua resposta\n","##\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=validation_ratio/(train_ratio+test_ratio), stratify=y_train, random_state=42)\n","\n","print(X_train.shape)\n","print(X_test.shape)\n","print(X_valid.shape)"],"metadata":{"id":"RQM_D8QzYRiE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler \n","## O MinMaxScaler transformará os dados para que fiquem no intervalo [0,1]\n","scaler = MinMaxScaler()\n","\n","## Iniciar a normalização dos dados. Primeiro fazer um 'fit' do scaler nos  \n","## dados de treino. Esta etapa visa \"aprender\" os parâmetros para normalização.\n","\n","### \n","# Adicione aqui a sua resposta\n","##\n","scaler.fit(X_train)\n","\n","## Aplicar a normalização nos três conjuntos de dados:\n","\n","### \n","# Adicione aqui a sua resposta\n","##\n","\n","X_train = scaler.transform(X_train)\n","X_test = scaler.transform(X_test)\n","X_valid = scaler.transform(X_valid)\n"],"metadata":{"id":"m5hC8OHiZCAt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Com os dados normalizados, podemos melhor inspecionar a distribuição de valores por classe, considerando o problema de classificação binário. Vamos fazer a análise para o conjunto de treino, observando as medianas para cada classe."],"metadata":{"id":"RyAocGK-dNoF"}},{"cell_type":"code","source":["df_train_norm =  pd.DataFrame(X_train,columns=features_names)\n","df_ytrain =  pd.DataFrame(y_train,columns=['quality'],dtype=int)\n","df_train_norm =  pd.concat([df_train_norm,df_ytrain], axis=1)\n","ave_values = df_train_norm.groupby(\"quality\").median()\n","ave_values.plot(kind=\"bar\",figsize=(15,7))"],"metadata":{"id":"yufMahVxeCM_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","\n","### Treinamento de modelos SVM com Kernel Linear\n","\n"],"metadata":{"id":"zuhzlay5bmQB"}},{"cell_type":"markdown","source":["Como vimos em aula, o modelo SVM com Kernel Linear é o \"mais simples\" dentre os modelos de SVM. Ele possui o hiperparâmetro C (termo de regularização), comum a todos os modelos de SVM, e que precisa ser otimizado para cada problema."],"metadata":{"id":"E0FaUD8G7jRN"}},{"cell_type":"markdown","source":["#### Otimização \"manual\" do hiperparâmetro C\n","No código abaixo, vamos fazer a otimização do hiperparâmetro C através da implementação de um loop. Para cada modelo, vamos avaliar a acurácia, recall e precisão. Vamos assumir que o melhor modelo será aquele que maximiza a acurácia."],"metadata":{"id":"T2an5tngpV4R"}},{"cell_type":"code","source":["## Definindo um array para armazenar o desempenho de cada modelo treinado e avaliado\n","perf_valid = []\n","\n","## Definindo valores de C a serem testados\n","param_grid_C = [0.1, 1, 5, 10, 50, 100] #valores para C, termo de regularização\n","\n","# Treinando e avaliado os modelos com cada valor de hiperparâmetro especificado\n","for ii in range(len(param_grid_C)):\n","    #clf = SVC(kernel='linear',C=param_grid_C[ii],random_state=42)#, class_weight='balanced') ##class_weight minimiza o efeito de termos mais exemplos para vinhos medíocres/ruins\n","    \n","    # clf = SVC(kernel='linear', C=param_grid_C[ii], random_state=42)\n","    clf = SVC(kernel='linear',C=param_grid_C[ii], class_weight='balanced',random_state=42)\n","\n","    clf.fit(X_train, y_train)\n","    pred_i = clf.predict(X_valid)\n","    perf_valid.append([param_grid_C[ii],accuracy_score(y_valid, pred_i),recall_score(y_valid, pred_i),precision_score(y_valid, pred_i)])"],"metadata":{"id":"b27Xz3zHqz60"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["perf_df = pd.DataFrame(perf_valid, columns=['C','accuracy','recall','precision'])\n","perf_df"],"metadata":{"id":"CrsT8OJBsglE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12, 6))\n","## Transforma o dataframe para facilitar plotar todas as métricas na mesma figura\n","perf_df_melt = pd.melt(perf_df, id_vars=['C'], value_vars=['accuracy','recall','precision'])\n","sns.lineplot(data=perf_df_melt,x='C',y='value',hue='variable',palette='muted',marker='o')"],"metadata":{"id":"LHx5_o0d0AbW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**>>> Responda:** Qual valor de C maximiza a acurácia? Como são os valores de acurácia, recall e precisão para este modelo?"],"metadata":{"id":"RFNNeYOh7fqU"}},{"cell_type":"markdown","source":["> ***Sua resposta aqui:*** Quando C é 10 a acurácia foi 0.732, variando pouco a partir disso. O valor de recall foi 0.855 e a precisão 0.439."],"metadata":{"id":"Fs5MNIOjCF5m"}},{"cell_type":"markdown","source":["**>>> Responda:** Qual o impacto de usar a opção `class_weight='balanced'` no código?"],"metadata":{"id":"IqIFtWSroFMb"}},{"cell_type":"markdown","source":["> ***Sua resposta aqui:*** através dessa opção foi possível encontrar os valores de precisão do modelo."],"metadata":{"id":"BFEUyyvKCIOi"}},{"cell_type":"markdown","source":["#### Otimização do hiperparâmetro C com GridSearchCV\n","\n","O scikit-learn disponibiliza o método GridSearchCV, que permite fazer a otimização de hiperparâmetros de forma mais automática. É especialmente útil quando queremos testar c**ombinações** de valores para diferentes hiperparâmetros. O código abaixo aplica o GridSearchCV usando as divisões de dados de treino e validação pré-definidas (através do método PredefinedSplit). Portanto, devemos chegar ao mesmo resultado da análise anterior. "],"metadata":{"id":"tmT8qRSW8MrA"}},{"cell_type":"code","source":["from sklearn.model_selection import PredefinedSplit, GridSearchCV ## para auxiliar na otimização de hiperparâmetros\n","\n","# Cria lista com os dados de treinamento com índice -1 e dados de validação com índice 0\n","# Concatena os dados de treino e validação com as partições pré-definidas\n","split_index = [-1]*len(X_train) + [0]*len(X_valid)\n","X_gridSearch = np.concatenate((X_train, X_valid), axis=0)\n","y_gridSearch = np.concatenate((y_train, y_valid), axis=0)\n","pds = PredefinedSplit(test_fold = split_index)\n","\n","## Define métricas de desempenho a serem estimadas\n","scoring = {'Accuracy':'accuracy', 'Precision': 'precision', 'Recall':'recall'} \n","\n","## Define o algoritmo base da otimização de hiperparâmetros\n","estimator = SVC(kernel='linear',class_weight='balanced')\n","\n","## Define a grid de hiperparâmetros a serem testados\n","param_grid = {'C': [0.1, 1, 5, 10, 50, 100]}#, 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n","\n","## Aplica GridSearch com as partições de treino/validação pré-definidas\n","gridS = GridSearchCV(estimator = estimator,\n","                   cv=pds,\n","                   param_grid=param_grid, \n","                   scoring=scoring,\n","                   refit='Accuracy', ##métrica a ser utilizada para definir o melhor modelo, retreinando-o com toda a base\n","                   return_train_score=True)\n","gridS.fit(X_gridSearch, y_gridSearch)\n","print('Desempenho máximo obtido com: {}'.format(gridS.best_params_))"],"metadata":{"id":"lLtKvrUwhQ3p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A visualização dos dados pode nos auxiliar a explorar o resultado da otimização de hiperparâmetros. O código abaixo criar um gráfico a partir dos resultados do GridSearchSV, focando na variação de um hiperparâmetro. Neste caso, analisamos C, o único hiperparâmetro variado na análise. (*OBS.: Não se preocupe se não entender todos os detalhes de implementação da função, ela é apenas um utilitário na visualização de dados*)"],"metadata":{"id":"OGqCgcp0nUpr"}},{"cell_type":"code","source":["## O código desta célula cria um gráfico de variação de desempenho de acordo com\n","## o valor do hiperparâmetro C.\n","\n","results = gridS.cv_results_\n","\n","plt.figure(figsize=(10, 7))\n","plt.title(\"Resultados do GridSearchCV\",\n","      fontsize=16)\n","\n","plt.xlabel(\"Hyperparameter\") ##nome do parâmetro a ser analisado\n","plt.ylabel(\"Performance\")\n","\n","ax = plt.gca()\n","\n","## Criar um numpy array para os resultados do hiperparâmetro a ser analisado.\n","## O hiperparâmetro C está identificado no objeto retornado pelo gridSearchCV\n","## como param_C\n","X_axis = np.array(results['param_C'].data, dtype=float)\n","\n","for scorer, color in zip(sorted(scoring), ['g', 'k', 'b', 'r']):\n","    for sample, style in (('train', '--'), ('test', '-')):\n","       sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n","       sample_score_std = results['std_%s_%s' % (sample, scorer)]\n","       ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n","                    sample_score_mean + sample_score_std,\n","                    alpha=0.1 if sample == 'test' else 0, color=color)\n","       ax.plot(X_axis, sample_score_mean, style, color=color,\n","            alpha=1 if sample == 'test' else 0.7,\n","            label=\"%s (%s)\" % (scorer, sample))\n","\n","    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n","    best_score = results['mean_test_%s' % scorer][best_index]\n","\n","    ## Plota uma linha vertical para o valor de hiperparâmetro que maximiza a métrica de desempenho\n","    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n","        linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n","    ## Anota o valor do melhor score\n","    ax.annotate(\"%0.3f\" % best_score,\n","            (X_axis[best_index], best_score + 0.008))\n","\n","plt.legend(loc=\"best\")\n","plt.grid(False)\n","plt.show()"],"metadata":{"id":"5g7w2L9b6Ml0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Visualização da fronteira de decisão de um SVM Linear"],"metadata":{"id":"nUxFeJBCp5zX"}},{"cell_type":"markdown","source":["Abaixo definimos uma funçao auxiliar para visualizar a fronteira de decisão dos classificadores, semelhante à que foi usada em outras atividades práticas."],"metadata":{"id":"bHRQDR0Okdkq"}},{"cell_type":"code","source":["## Fonte: https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Utilities/ML-Python-utils.py\n","def plot_decision_boundaries(X, y, limit, model_class, **model_params):\n","    \"\"\"\n","    Function to plot the decision boundaries of a classification model.\n","    This uses just the first two columns of the data for fitting \n","    the model as we need to find the predicted value for every point in \n","    scatter plot.\n","    Arguments:\n","            X: Feature data as a NumPy-type array.\n","            y: Label data as a NumPy-type array.\n","            model_class: A Scikit-learn ML estimator class \n","            e.g. GaussianNB (imported from sklearn.naive_bayes) or\n","            LogisticRegression (imported from sklearn.linear_model)\n","            **model_params: Model parameters to be passed on to the ML estimator\n","    \n","    Typical code example:\n","            plt.figure()\n","            plt.title(\"KNN decision boundary with neighbros: 5\",fontsize=16)\n","            plot_decision_boundaries(X_train,y_train,KNeighborsClassifier,n_neighbors=5)\n","            plt.show()\n","    \"\"\"\n","    try:\n","        X = np.array(X)\n","        y = np.array(y).flatten()\n","    except:\n","        print(\"Coercing input data to NumPy arrays failed\")\n","\n","    # Reduces to the first two columns of data - for a 2D plot!\n","    reduced_data = X[:, :2]\n","    # Instantiate the model object\n","    model = model_class(**model_params)\n","    # Fits the model with the reduced data\n","    model.fit(reduced_data, y)\n","\n","    # Step size of the mesh. Decrease to increase the quality of the VQ.\n","    h = .02     # point in the mesh [x_min, m_max]x[y_min, y_max].    \n","\n","    # Plot the decision boundary. For that, we will assign a color to each\n","    x_min, x_max = reduced_data[:, 0].min() - limit, reduced_data[:, 0].max() + limit\n","    y_min, y_max = reduced_data[:, 1].min() - limit, reduced_data[:, 1].max() + limit\n","    # Meshgrid creation\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n","\n","    # Obtain labels for each point in mesh using the model.\n","    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])    \n","\n","    x_min, x_max = X[:, 0].min() - limit, X[:, 0].max() + limit\n","    y_min, y_max = X[:, 1].min() - limit, X[:, 1].max() + limit\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n","                         np.arange(y_min, y_max, 0.01))\n","\n","    # Predictions to obtain the classification results\n","    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n","\n","    # Plotting\n","    plt.contourf(xx, yy, Z, alpha=0.2,cmap='viridis')\n","    g=plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.6,s=50, edgecolor='k', cmap='viridis' )\n","    plt.xlabel(\"Feature-1\",fontsize=15)\n","    plt.ylabel(\"Feature-2\",fontsize=15)\n","    plt.xticks(fontsize=14)\n","    plt.yticks(fontsize=14)\n","    plt.legend(handles=g.legend_elements()[0],labels=('0','1'))\n","    return plt"],"metadata":{"id":"-L0Xl1p9kiHC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualizamos abaixo a fronteira de decisão para o modelo SVM com Kernel Linear. É importante atentar para o fato de que este exemplo visual se baseia apenas em dois atributos para manter o problema em duas dimensões, e assim facilitar a visualização. Assim, este modelo **não representa** exatamente o modelo treinado acima, é apenas um exemplo de como a fronteira de decisão deste modelo SVM Linear poderia se comportar nos dados. Além disso, para melhorar a visualização usamos apenas as primeiras 100 instâncias do conjunto de dados."],"metadata":{"id":"I_KB1-VeAV2w"}},{"cell_type":"code","source":["## Visualizar a fronteira de decisão para o modelo SVM com kernel linear. \n","## >>> Ajuste o valor de C para o melhor valor encontrado o GridSearchCV (1 é o valor padrão)\n","plot_decision_boundaries(X_train[1:100,], y_train[1:100], 0.1, SVC, kernel='linear',class_weight='balanced',C=10)"],"metadata":{"id":"Be6JMI0S-wLa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**>>> Exercício:** Com base no melhor valor do hiperparâmetro C encontrado na análise do GridSearch para o SVM Linear, aplique o modelo para classificação nos dados de teste (X_test), avaliando o seu desempenho com as métricas de acurácia, recall e precisão (opcionalmente, avalie também a matriz de confusão).\n","\n","OBS.: O método `GridSearchCV` com opção `refit=True` ou `refit='Accuracy'` (ou outra métrica de desempenho) realiza o treinamento de um modelo com toda a base informada na função `.fit()`. No nosso caso, se refere aos dados de treino e validação."],"metadata":{"id":"5F-IXUuA9g8E"}},{"cell_type":"code","source":["### \n","# Adicione aqui a sua resposta\n","##\n","\n","# Opção 1: rodando novamente SVC com C ótimo = 10\n","print(\"Opção 1\")\n","clf_10 = SVC(kernel='linear',C=10, class_weight='balanced',random_state=42)\n","clf_10.fit(X_train, y_train)\n","\n","pred_10 = gridS.predict(X_test)\n","\n","print(accuracy_score(y_test, pred_10))\n","print(recall_score(y_test, pred_10))\n","print(precision_score(y_test, pred_10))\n","\n","cm = confusion_matrix(y_test, pred_10 ,labels=clf_10.classes_)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf_10.classes_)\n","disp = disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n","plt.grid(False)\n","plt.show()\n","\n","# Opção 2: utilizando o pŕoprio modelo  ótimo gridS (GridSearchCV)\n","print(\"Opção 2\")\n","pred_10_gridS = gridS.predict(X_test)\n","\n","print(accuracy_score(y_test, pred_10_gridS))\n","print(recall_score(y_test, pred_10_gridS))\n","print(precision_score(y_test, pred_10_gridS))\n","\n","cm = confusion_matrix(y_test, pred_10_gridS ,labels=gridS.classes_)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gridS.classes_)\n","disp = disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n","plt.grid(False)\n","plt.show()"],"metadata":{"id":"QhXEexIl9gfz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","\n","### Comparando diferentes funções de Kernel no SVM\n","\n","\n","Nesta seção, vamos comparar diferentes tipos de Kernel em um algoritmo SVM. Utilizaremos o método GridSearchCV do scikit-learn pela praticidade do mesmo. Entretanto, também seria possível realizar a mesma análise com um loop definido por nós, testando diferentes combinações de valores de hiperparâmetros."],"metadata":{"id":"HxJy8wbS-k-n"}},{"cell_type":"code","source":["from sklearn.model_selection import PredefinedSplit, GridSearchCV ## para auxiliar na otimização de hiperparâmetros\n","\n","\n","## Cria lista com os dados de treinamento com índice -1 e dados de validação com índice 0\n","## Concatena os dados de treino e validação com as partições pré-definidas\n","split_index = [-1]*len(X_train) + [0]*len(X_valid)\n","X_gridSearch = np.concatenate((X_train, X_valid), axis=0)\n","y_gridSearch = np.concatenate((y_train, y_valid), axis=0)\n","pds = PredefinedSplit(test_fold = split_index)\n","\n","# ## Define métricas de desempenho a serem estimadas\n","scoring = {'Accuracy':'accuracy', 'Precision': 'precision', 'Recall':'recall'} \n","\n","## Define o algoritmo base da otimização de hiperparâmetros\n","estimator = SVC(class_weight='balanced')\n","\n","## Define a grid de hiperparâmetros a serem testados\n","param_grid = {'C': [0.1, 1, 5, 10, 50, 100], 'kernel': ['rbf', 'poly', 'sigmoid']}#,'gamma': [1,0.1,0.01,0.001]} ## gamma foi removido para reduzir tempo de execução\n","\n","## Aplica GridSearch com as partições de treino/validação pré-definidas\n","gridS2 = GridSearchCV(estimator = estimator,\n","                   cv=pds,\n","                   param_grid=param_grid, \n","                   scoring=scoring,\n","                   refit='Accuracy', ##métrica a ser utilizada para definir o melhor modelo, retreinando-o com toda a base\n","                   return_train_score=True)\n","gridS2.fit(X_gridSearch, y_gridSearch)\n","print('Desempenho máximo obtido com: {}'.format(gridS2.best_params_))"],"metadata":{"id":"6wfQR6I9BfmI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred_cv = gridS2.predict(X_test)\n","cm = confusion_matrix(y_test, y_pred_cv ,labels=gridS2.classes_)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gridS2.classes_)\n","disp = disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n","plt.grid(False)\n","plt.show()"],"metadata":{"id":"Y1Wi7-LBDd0X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = gridS2.cv_results_\n","\n","plt.figure(figsize=(10, 7))\n","plt.title(\"Resultados do GridSearchCV\",\n","      fontsize=16)\n","\n","plt.xlabel(\"Hyperparameter\") ##nome do parâmetro a ser analisado\n","plt.ylabel(\"Performance\")\n","\n","ax = plt.gca()\n","\n","## Criar um numpy array para os resultados do hiperparâmetro a ser analizado\n","X_axis = np.array(results['param_kernel'].data)#, dtype=float)\n","\n","for scorer, color in zip(sorted(scoring), ['g', 'k', 'b', 'r']):\n","    for sample, style in (('train', '--'), ('test', '-')):\n","       sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n","       sample_score_std = results['std_%s_%s' % (sample, scorer)]\n","       ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n","                    sample_score_mean + sample_score_std,\n","                    alpha=0.1 if sample == 'test' else 0, color=color)\n","       ax.plot(X_axis, sample_score_mean, style, color=color,\n","            alpha=1 if sample == 'test' else 0.7,\n","            label=\"%s (%s)\" % (scorer, sample))\n","\n","    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n","    best_score = results['mean_test_%s' % scorer][best_index]\n","\n","    ## Plota uma linha vertical para o valor de hiperparâmetro que maximiza a métrica de desempenho\n","    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n","        linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n","    ## Anota o valor do melhor score\n","    ax.annotate(\"%0.3f\" % best_score,\n","            (X_axis[best_index], best_score + 0.008))\n","\n","plt.legend(loc=\"best\")\n","plt.grid(False)\n","plt.show()"],"metadata":{"id":"joNArdzPB4qr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**>>> Responda:** Qual foi a melhor configuração de hiperparâmetros encontrada pelo GridSearchCV? Qual o respectivo desempenho?"],"metadata":{"id":"bXGWHx4rCh56"}},{"cell_type":"markdown","source":["> ***Sua resposta aqui:*** Para precisão e acurácia os melhores valores foram encontrados com o hiperparâmetro poly, precision = 0.460 e accuracy = 0.752. E o melhor valor de recall foi encontrado para o hiperperâmetro rfb, recall = 0.881."],"metadata":{"id":"k9sDdkbnreey"}},{"cell_type":"markdown","source":["A fim de entender como a fronteira de decisão muda para um kernel RBF ou Polinomial em relação ao kernel Linear, vamos visualizá-la para uma amostra dos dados."],"metadata":{"id":"rR5vyAD-DawS"}},{"cell_type":"code","source":["## Visualizar a fronteira de decisão para o melhor modelo SVM\n","## Ajuste o valor de C e gamma para o melhor valor encontrado o GridSearchCV (1 e 'auto' são valores padrões)\n","#plot_decision_boundaries(X_train[1:100,], y_train[1:100], 0.1, SVC, kernel='rbf',class_weight='balanced',C=1,gamma='auto')\n","plot_decision_boundaries(X_train[1:100,], y_train[1:100], 0.1, SVC, kernel='poly',class_weight='balanced',C=10,gamma='auto')"],"metadata":{"id":"wV8lyaLPIP1N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Opcional:** Para o tipo de Kernel que apresentar o melhor desempenho na análise realizada, estenda o estudo de impacto de hiperparâmetros para otimizar o valor de gamma."],"metadata":{"id":"ylnY97A3O9Jj"}},{"cell_type":"markdown","source":["**>>> Exercício:** Avalie o desempenho do melhor modelo sobre os dados de teste. Compare o resultado com o desempenho obtido com o SVM Linear, discutindo se a acurácia, precisão e recall melhoraram/pioraram, bem como se o modelo foi capaz de aumentar TP/TN ou diminuir FP/FN.\n"],"metadata":{"id":"jcLVhKN3PXMz"}},{"cell_type":"code","source":["### \n","# >>> Adicione aqui a sua resposta\n","##\n","# Método linear: gridS (GridSearchCV)\n","print(\"Modelo ótimo linear  {'C': 10}\")\n","pred_10_gridS = gridS.predict(X_test)\n","\n","print(accuracy_score(y_test, pred_10_gridS))\n","print(recall_score(y_test, pred_10_gridS))\n","print(precision_score(y_test, pred_10_gridS))\n","\n","cm = confusion_matrix(y_test, pred_10_gridS ,labels=gridS.classes_)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gridS.classes_)\n","disp = disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n","plt.grid(False)\n","plt.show()\n","\n","print(\"Modelo ótimo não linear {'C': 0.1, 'kernel': 'poly'}\")\n","y_pred_cv = gridS2.predict(X_test)\n","print(accuracy_score(y_test, y_pred_cv))\n","print(recall_score(y_test, y_pred_cv))\n","print(precision_score(y_test, y_pred_cv))\n","\n","\n","y_pred_cv = gridS2.predict(X_test)\n","cm = confusion_matrix(y_test, y_pred_cv ,labels=gridS2.classes_)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gridS2.classes_)\n","disp = disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n","plt.grid(False)\n","plt.show()\n","\n","print(\"Análise:\")\n","\n","print(\"Os valores de acurácia e precisão melhoraram, apesar do valor de recall piorar.\")\n","print(\"O modelo linear se mostrou melhor na classificação dos VP, 115 contra 110 do modelo não linear.\")\n","print(\"Enquanto o modelo não linear se mostrou melhor na classificação dos VN, 429 contra 405 do modelo linear.\")\n"],"metadata":{"id":"XMx9viWORRCA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","## Sua vez\n","\n","\n","\n","Desenvolva um modelo preditivo interpretando o problema como uma tarefa de regressão, ao invés de uma classificação. Faça uso de um modelo SVM Regressor (SVR) e avalie o desempenho com as métricas **Mean Absolute Error** e **R2**, disponíveis no scikit-learn. Para fins de referência, os autores do artigo no qual os dados originais foram publicados desenvolveram um modelo SVM que obteve MAE de 0.45.\n","\n","Faça também uma avaliação da acurácia do modelo seguindo estratégia similar a dos autores: considerando um nível de tolerância $T$, a saída predita pelo modelo $ŷ_i$ pode ser transformada em uma categoria $p_i$ (neste caso, notas inteiras entre 0 e 10) através do seguinte critério:\n","$ pi = y_i$, se $|y_i − ŷ_i| ≤ T$, senão $p_i = y_i′$, onde  $y_i′$ denota a classe mais próxima de $ŷ_i$. Por exemplo, supondo $ŷ_i = 4.9$ e $T = 0.25$, como $|5.0 - 4.9| = 0.1 ≤ 0.25$, esta instância seria categorizada como 5. No caso de $ŷ_i = 4.4$ e o mesmo nível de tolerância, como a comparação de $ŷ_i$ com os valores 4 e 5 não atendem ao critério de tolerância, a classe predita será a mais próxima de 4.4, ou seja, 4. Experimente para T=0.25 e, opcionalmente, para T=0.5.\n","\n","Dicas para o exercício:\n","\n","\n","*   Utilize o método [SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html?highlight=svr#sklearn.svm.SVR) do Scikit-learn (`from sklearn.svm import SVR`). O método tem os mesmos argumentos que foram utilizados para o caso da classificação. \n","*   O modelo SVR pode ser otimizada com o uso de GridSearchCV e PredefinedSplits, semelhante ao que foi feito para o modelo de classificação binária neste notebook.\n","*   As métricas de avaliação de modelos sugeridas podem ser importadas através do comando `from sklearn.metrics import mean_absolute_error, r2_score`. Para avaliar o R2, por exemplo, utilize `r2_score(y_test, y_pred)`\n","*   Utilize um scatterplot para comparar os valores preditos com os valores reais.\n","\n"],"metadata":{"id":"x0wP4Go7TI_r"}},{"cell_type":"markdown","source":["> ***Sua vez:*** "],"metadata":{"id":"8ZaqgrhVMvW1"}},{"cell_type":"code","source":["from sklearn.svm import SVR\n","from sklearn.metrics import mean_absolute_error, r2_score\n","\n","# recarrega dados\n","df = pd.read_table(\"https://drive.google.com/uc?export=view&id=11YsVJck74_gyADzGJSU9Uwn8cDq_l3BD\",sep=\";\")\n","\n","## Separa o dataset em duas variáveis: os atributos/entradas (X) e a classe/saída (y)\n","X = df.drop(['quality'], axis=1)\n","y = df['quality'].values\n","\n","## Definindo as proporções de treino, validação e teste.\n","train_ratio = 0.70\n","test_ratio = 0.15\n","validation_ratio = 0.15\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, stratify=y, random_state=42)\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=validation_ratio/(train_ratio+test_ratio), stratify=y_train, random_state=42)\n","\n","## Normaliza os dados\n","scaler = MinMaxScaler()\n","scaler.fit(X_train)\n","X_train = scaler.transform(X_train)\n","X_test = scaler.transform(X_test)\n","X_valid = scaler.transform(X_valid)\n","\n","## Cria lista com os dados de treinamento com índice -1 e dados de validação com índice 0\n","## Concatena os dados de treino e validação com as partições pré-definidas\n","split_index = [-1]*len(X_train) + [0]*len(X_valid)\n","X_gridSearch = np.concatenate((X_train, X_valid), axis=0)\n","y_gridSearch = np.concatenate((y_train, y_valid), axis=0)\n","pds = PredefinedSplit(test_fold = split_index)\n","\n","# ## Define métricas de desempenho a serem estimadas\n","scoring = {'MAE':'neg_mean_absolute_error', 'R2': 'r2'}\n","\n","## Define o algoritmo base da otimização de hiperparâmetros\n","estimator = SVR()\n","\n","## Define a grid de hiperparâmetros a serem testados\n","param_grid = {'C': [0.1, 1, 5, 10, 20], 'gamma': [1,0.1,0.01,0.001], 'kernel': ['rbf', 'poly', 'linear']} # muito lento com muitos parametros\n","#param_grid = {'C': [0.1, 1, 5, 10, 50, 100]}\n","\n","## Aplica GridSearch com as partições de treino/validação pré-definidas\n","gridS3 = GridSearchCV(estimator = estimator,\n","                   cv=pds,\n","                   param_grid=param_grid, \n","                   scoring=scoring,\n","                   refit='MAE', ##métrica a ser utilizada para definir o melhor modelo, retreinando-o com toda a base\n","                   return_train_score=True)\n","gridS3.fit(X_gridSearch, y_gridSearch)\n","print('Desempenho máximo obtido com: {}'.format(gridS3.best_params_))\n"],"metadata":{"id":"2wCnxdDoMkRn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## testando predição: r2_score\n","y_pred_svr = gridS3.predict(X_test)\n","print(r2_score(y_test, y_pred_svr))\n","\n","# plotando valores preditos com valores reais\n","print('Antes do agrupamento dos valores em classes')\n","plt.scatter(y_test, y_pred_svr, color = 'red')\n","plt.xlabel('True')\n","plt.ylabel('Predicted')\n","plt.show()\n","\n","# de-para de valores T=0.25\n","#print(y_pred_svr)\n","T = 0.25\n","y_pred_svr_T = []\n","faixas = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n","\n","for y in y_pred_svr:\n","  # print('valor: ', format(y))\n","  atribui = -1 # valor a ser atribuido\n","  proximidade = 1 # grau proximidade\n","  for y_faixa in faixas:\n","    if abs(y_faixa - y) < proximidade:\n","      proximidade = abs(y_faixa - y) # atualiza grau proximidade\n","      y_proximo = y_faixa\n","    if abs(y_faixa - y) < T: # | y_pred - y | < T Então atribui y_pred\n","      atribui = y_faixa\n","      break\n","  if atribui == -1: # se não encontrou valor pelo T, atribui y_proximo\n","    atribui = y_proximo\n","  # print('valor: ', y, ' - atribui: ', atribui)\n","  y_pred_svr_T.append(atribui)\n","\n","print('Depois do agrupamento dos valores em classes')\n","plt.scatter(y_test, y_pred_svr_T, color = 'red')\n","plt.xlabel('True')\n","plt.ylabel('Predicted')\n","plt.show()\n","\n","print('Matriz de confusão')\n","cm = confusion_matrix(y_test, y_pred_svr_T) # como visualizar os labels corretos?\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm) # como visualizar os labels corretos?\n","disp = disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n","plt.grid(False)\n","plt.show()\n","\n","  \n"],"metadata":{"id":"o31tT4VwdIoH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","\n","\n","#### Sugestões de experimentos extras:\n","\n","*  Explore o hiperparâmetro class_weights, tentando outros pesos e observando o impacto sobre o desempenho do modelo.\n","*   Tente aplicar o modelo desenvolvido ao conjunto de dados de [vinhos verdes tintos](https://drive.google.com/file/d/1wkvrdgqXRXrA9Tk2lV0K-cOjf4vSQh8U/view?usp=sharing), que possui as mesmas propriedades analisadas, entretanto, difere dos dados usados neste exercício por ser do tipo tinto. Aplique seu modelo de SVR (Regressor) ou o modelo de SVM para classificação binária desenvolvido nesta atividade. O desempenho preditivo para este novo conjunto de dados é tão bom quanto o obtido para os dados de teste (15% da base original)? Caso não seja bom, reflita sobre o possível motivo deste resultado.  Você acha que o desempenho poderia melhorar ao se desenvolver um modelo a partir da união das bases de vinhos verdes brancos e tintos? Para fazer download dos dados no notebook, use o seguinte comando: `df = pd.read_table(\"https://drive.google.com/uc?export=view&id=1wkvrdgqXRXrA9Tk2lV0K-cOjf4vSQh8U\",sep=\";\")`."],"metadata":{"id":"ve0iOG0Qp4Hg"}}]}