{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Aula07_introEnsemble_atividades_Hua.ipynb","provenance":[{"file_id":"1IyC9pO9i7pPHJvhX7v3V--_LD8S87yOa","timestamp":1653397294267},{"file_id":"1E4uX64ue8qdLr9-pPAnGRAyr-7R2vTMB","timestamp":1643573144875},{"file_id":"11KQaF5WWqgKOnoSWPy6kP3U46mZIkaPD","timestamp":1643397530200}],"collapsed_sections":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Especialização em Ciência de Dados - INF/UFRGS E SERPRO**\n","### Disciplina CD003 - Aprendizado Supervisionado\n","#### *Profa. Mariana Recamonde-Mendoza (mrmendoza@inf.ufrgs.br)*\n","<br> \n","\n","---\n","***Observação:*** *Este notebook é disponibilizado aos alunos como complemento às aulas síncronas e aos slides preparados pela professora. Desta forma, os principais conceitos são apresentados no material teórico fornecido. O objetivo deste notebook é reforçar os conceitos e demonstrar questões práticas no uso de diferentes algoritmos e estratégias de Aprendizado de Máquina.*\n","\n","\n","---\n","\n"],"metadata":{"id":"piZunEaUizIm"}},{"cell_type":"markdown","source":["<br>\n","\n","## **Aula 07** - **Tópico: Introdução ao Aprendizado Ensemble**\n","\n","<br>\n","\n","No que diz respeito a tomada de decisão em tarefas preditivas, **\"ouvir a opinião\" de um conjunto de árvores de decisão** pode trazer alguma vantagem em termos de desempenho preditivo?\n","\n","***Vamos investigar essa possibilidade?***\n","\n","*Observação: O desenvolvimento deste notebook foi baseado no livro de Aurélien Géron, Hands-On Machine Learning with Scikit-Learn, Keras and Tensorflow (2nd Edition)*\n","\n","----\n"],"metadata":{"id":"JYZWwEfo3H1R"}},{"cell_type":"markdown","source":["###Carregando e dividindo os dados\n","\n","\n","Neste notebook, vamos utilizar novamente o dataset [Breast Cancer Wisconsin](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset), carregando-o através das funções do scikit-learn."],"metadata":{"id":"owi-J_whK4IS"}},{"cell_type":"code","source":["import pandas as pd             # biblioteca para análise de dados \n","import matplotlib.pyplot as plt # biblioteca para visualização de informações\n","import seaborn as sns           # biblioteca para visualização de informações\n","import numpy as np              # biblioteca para operações com arrays multidimensionais\n","from sklearn.datasets import load_breast_cancer ## conjunto de dados a ser analisado\n","sns.set()\n","\n","data = load_breast_cancer() ## carrega os dados de breast cancer\n","X = data.data  # matriz contendo os atributos\n","y = data.target  # vetor contendo a classe (0 para maligno e 1 para benigno) de cada instância\n","feature_names = data.feature_names  # nome de cada atributo\n","target_names = data.target_names  # nome de cada classe\n","\n","## Relembrando as características do dataset\n","print(f\"Dimensões de X: {X.shape}\\n\")\n","print(f\"Dimensões de y: {y.shape}\\n\")\n","print(f\"Nomes dos atributos: {feature_names}\\n\")\n","print(f\"Nomes das classes: {target_names}\")"],"metadata":{"id":"p-1VZTPjQax2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Iniciamos fazendo uma divisão dos dados em treino e teste na proporção 80%/20%. Fazemos de forma estratificada, isto é, mantendo a proporção original das classes ('stratify=y')."],"metadata":{"id":"sR11BS-7bYde"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split \n","\n","## Fazemos a divisão com 2-way holdout, de forma estratificada\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"],"metadata":{"id":"cIuIq4oSMVtk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["O método ShuffleSplit facilita a divisão dos dados em um número pré-determinado de conjuntos de treino e teste, cada par independente entre si. Para mais informações sobre o método, veja [este link](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html)."],"metadata":{"id":"9MmyDlwNPtYw"}},{"cell_type":"code","source":["from sklearn.model_selection import ShuffleSplit \n","\n","n_trees = 501\n","n_instances = 100\n","\n","mini_sets = []\n","\n","# 501 árvores a partir de um conjunto limitado de dados\n","\n","# amostrando 501 conjunto de dados com 100 instancias aleatorias (a partir dos 80% p/ treino)\n","## cria diversos conjuntos de treino/teste indepenedentes\n","## deixa 'n_instances' instâncias para treinamento\n","rs = ShuffleSplit(n_splits=n_trees, test_size=len(X_train) - n_instances, random_state=42)\n","# 100 instâncias para treino\n","\n","for mini_train_index, mini_test_index in rs.split(X_train):\n","    X_mini_train = X_train[mini_train_index]\n","    y_mini_train = y_train[mini_train_index]\n","    mini_sets.append((X_mini_train, y_mini_train))"],"metadata":{"id":"5VHnz-K6Ge4_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Treinando múltiplas árvores de decisão"],"metadata":{"id":"ST8n9jwzndyN"}},{"cell_type":"markdown","source":["A seguir, vamos realizar a otimização de hiperparâmetros de uma árvore de decisão utilizando a função GridSearchCV. Para agilizar o processo a ser executado em aula, vamos adotar duas simplificações: i) iremos testar um número limitado de combinações de valores para os hiperparâmetros, ii) vamos estimar os melhores valores de hiperparâmetros com base nos dados X_train e depois vamos 'copiar' estes valores para 501 novas árvores a serem treinadas nos dados amostrados. Isto garante que todas as árvores utilizarão a melhor configuração de hiperparâmetros encontrada, mas cada árvore será treinada com base em uma amostra específica dos dados (1 dentre as 501 geradas)."],"metadata":{"id":"YjXf9VsEb0a3"}},{"cell_type":"code","source":["from sklearn.base import clone\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","## otimiza os hiperparâmetros do algoritmo de árvores de decisão usando\n","## função GridSearchCV do scikit-learn e X_train.\n","params = {'max_depth': list(range(2, 6)), 'min_samples_split': [2, 3, 4]}\n","grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=3)\n","grid_search_cv.fit(X_train, y_train)\n","print(grid_search_cv.best_params_)\n","\n","## constrói um novo 'estimador' do scikit-learn com os mesmos hiperparâmetros\n","## mas sem estar ajustados aos dados (ou seja, não copia os dados, apenas hiperparâmetros)\n","setTrees = [clone(grid_search_cv.best_estimator_) for _ in range(n_trees)] # 501 cópias\n"],"metadata":{"id":"P_V5PNNGGgw_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## faz o treinamento de cada uma das 'n_trees' árvores\n","accuracy_scores = []\n","proba_all = []\n","for tree, (X_mini_train, y_mini_train) in zip(setTrees, mini_sets):\n","    tree.fit(X_mini_train, y_mini_train)\n","    \n","    y_pred = tree.predict(X_test)\n","    proba_all.append(tree.predict_proba(X_test)[:,0])\n","    accuracy_scores.append(accuracy_score(y_test, y_pred))"],"metadata":{"id":"4n34qv1rXEqg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como foi a variação de desempenho entre as árvores? Podemos analisar a acurácia média e a distribuição das acurácias entre as 501 árvores. A mesma análise poderia ser feita para outras medidas de desempenho."],"metadata":{"id":"alLJbdxwhD01"}},{"cell_type":"code","source":["np.mean(accuracy_scores)"],"metadata":{"id":"4ny3KqcfhLDe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ax= sns.boxplot(y=accuracy_scores)\n","ax.set_ylabel(\"Acurácia\")"],"metadata":{"id":"dLCTYbGcYweY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Também é interessante observar como estas árvores variam entre as predições para os dados de teste (X_test, que são os mesmos para todas as árvores). Vamos criar um heatmap (mapa de calor), usando a probabilidade para a classe 0 (que representa tumor maligno, neste notebook)."],"metadata":{"id":"gsMo1Me6hNF2"}},{"cell_type":"code","source":["print(len(proba_all))\n","print(len(proba_all[1]))\n","\n","## transforma lista em array, para plotar heatmap\n","proba_all_array = np.asarray(proba_all)\n","print(proba_all_array.T.shape) ## obtém o tamanho da transposta do array/matriz"],"metadata":{"id":"7KMOqXPAdNcH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A seguir vamos usar um heatmap (mapa de calor) para visualizar as diferenças nas predições entre as várias árvores. As linhas representam as instâncias de teste e as colunas as árvores treinadas."],"metadata":{"id":"cC_ISu_DdKRL"}},{"cell_type":"code","source":["## Visualizando as probabilidades para a classe 0.\n","## Quanto mais próximo de 1, mais provável de ser da classe \"Maligno\"\n","fig, ax = plt.subplots(figsize=(16, 16))\n","ax = sns.heatmap(proba_all_array.T,vmin=0, vmax=1,cmap=\"YlGnBu\")\n","ax.set(xticklabels=[],yticks=list(range(0,114,2)))\n","plt.xlabel('Trees')\n","plt.ylabel('Test instances')\n","plt.show()"],"metadata":{"id":"mkuLuqDZdzFS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Analise como as árvores possuem diferenças entre si para as instâncias analisadas. Em alguns casos, a predição possui uma clara concordância entre todas as árvores. Em outros, algumas árvores discordam em relação à classe de uma dada instância. Essa diversidade de opiniões pode tornar a tomada de decisão melhor e mais robusta, se houver uma forma apropriada de combinar as opiniões."],"metadata":{"id":"GnnjsVFlhltQ"}},{"cell_type":"markdown","source":["###Agregando as predições de múltiplos classificadores"],"metadata":{"id":"K3m8S_WhnfWC"}},{"cell_type":"markdown","source":["Vamos avaliar o desempenho ao se agregar a decisão destas árvores. Vamos assumir que a saída da tomada de decisão conjunta será com base na **classe mais votada** entre todas as árvores."],"metadata":{"id":"vWM97-87h4nd"}},{"cell_type":"code","source":["Y_pred = np.empty([n_trees, len(X_test)], dtype=np.uint8)\n","\n","## agrega a classe predita por todas as árvores em um array de 2D\n","for tree_index, tree in enumerate(setTrees):\n","    Y_pred[tree_index] = tree.predict(X_test)\n","\n","## observando a saída gerada para as duas primeiras instâncias de teste \n","print(Y_pred[:2,:])"],"metadata":{"id":"ZGDDhAaUGjFM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.stats import mode\n","\n","## determina a saída a partir da moda (valor mais frequente)\n","y_pred_majority_votes, n_votes = mode(Y_pred, axis=0)\n","\n","## observa a classe predita pela abordagem de votação\n","print(y_pred_majority_votes)"],"metadata":{"id":"V10_WpqMGj9G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## número de votos que cada classe recebeu.\n","## é possível perceber a correlação com a análise do heatmap\n","print(n_votes)"],"metadata":{"id":"By2MXxCJisX8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## avalia o desempenho desta classificação a partir de uma votação majoritária\n","acc_voting = accuracy_score(y_test, y_pred_majority_votes.reshape([-1]))\n","print(acc_voting)"],"metadata":{"id":"C4mdOXxHGk5e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Podemos comparar o desempenho do método de votação (que agrega múltiplas saídas) com o desempenho entre as 501 árvores treinadas e avaliadas. A agregação de modelos pode trazer benefícios nas tarefas de análise preditiva, e existe toda uma teoria por traz desta estratégia denominada **wisdom of crowds** (**sabedoria das multidões**).\n","\n","O exercício desenvolvido neste notebook é praticamente uma implementação \"manual\" do algoritmo de Florestas Aleatórias, com algumas diferenças propostas pelo algoritmo que iremos estudar a seguir."],"metadata":{"id":"oOw61uAtjHfN"}}]}