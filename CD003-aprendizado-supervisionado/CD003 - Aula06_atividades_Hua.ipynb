{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CD003 - Aula06_atividades_Hua.ipynb","provenance":[{"file_id":"1aN2365fvvIFmuFgIHHR0-qB1x-v1YEV5","timestamp":1653055432309},{"file_id":"1E4uX64ue8qdLr9-pPAnGRAyr-7R2vTMB","timestamp":1643573144875},{"file_id":"11KQaF5WWqgKOnoSWPy6kP3U46mZIkaPD","timestamp":1643397530200}],"collapsed_sections":[],"private_outputs":true,"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Especialização em Ciência de Dados - INF/UFRGS e SERPRO**\n","### Disciplina CD003 - Aprendizado Supervisionado\n","#### *Profa. Mariana Recamonde-Mendoza (mrmendoza@inf.ufrgs.br)*\n","<br> \n","\n","---\n","***Observação:*** *Este notebook é disponibilizado aos alunos como complemento às aulas síncronas e aos slides preparados pela professora. Desta forma, os principais conceitos são apresentados no material teórico fornecido. O objetivo deste notebook é reforçar os conceitos e demonstrar questões práticas no uso de diferentes algoritmos e estratégias de Aprendizado de Máquina. O desenvolvimento deste notebook teve o auxílio do mestrando Thomas Fontanari.*\n","\n","\n","---"],"metadata":{"id":"piZunEaUizIm"}},{"cell_type":"markdown","source":["<br>\n","\n","## **Aula 06** - **Tópico: Árvores de Decisão**\n","\n","<br>\n","\n","As árvores de decisão são modelos amplamente conhecidos pela sua inerente interpretabilidade, podendo ser aplicados para tarefas de classificação e regressão. A estrutura de uma árvore de decisão é bastante simples, podendo ser transcrita como um conjunto de regras, cada qual definida pelo caminho percorrido do nó raiz a um nó folha. Entretanto, o algoritmo possui a capacidade de modelar fronteiras de decisão bastante complexas. Apesar destas vantagens, o algoritmo apresenta duas desvantagens importantes: é muito suscetível ao fenômeno de *overfitting* (sobreajuste aos dados) e muito sensível a variações nos dados de treinamento. \n","\n","Nessa atividade, vamos explorar árvores de decisão a fim de ver exemplos práticos de suas principais vantagens e desvantagens. Também exploraremos técnicas de pré-poda e pós-poda para controlar a complexidade do modelo e reduzir as chances de overfitting.\n","\n","<br> \n","\n","**Objetivo deste notebook**: Explorar o uso de árvores de decisão para tarefas preditivas, compreendendo seu potencial de interpretabilidade. Avaliar a sensibilidade do modelo a variações nos dados e o impacto de estratégias de regularização do modelo, ao restringir a liberdade do algoritmo de modelar a árvore durante o treinamento do modelo ou realizar pós-poda.\n","\n","<br>\n","\n","---\n","\n"],"metadata":{"id":"UoeSV08X1_mm"}},{"cell_type":"markdown","source":["##**Um novo preditor para o diagnóstico de Câncer de Mama**\n","\n","Para esta atividade, vamos retomar o conjunto de dados sobre câncer de mama usado na Aula 02 (KNN). Lembrando: cada instância se refere ao exame de um(a) paciente e os atributos são computados a partir de uma imagem digitalizada de material coletado de uma massa mamária através de uma punção aspirativa por agulha fina (PAAF), descrevendo as características dos núcleos celulares presentes na imagem. O objetivo da tarefa é ser capaz de prever se o tumor é maligno ou benigno a partir destas características.\n","\n","Um total de dez características foram extraídas para cada núcleo celular:\n","\n","*   raio (média das distâncias do centro aos pontos do perímetro)\n","*   textura (desvio padrão dos valores de escala de cinza)\n","*   perímetro\n","*   área\n","*   suavidade (variação local nos comprimentos dos raios)\n","*   compacidade (perímetro^2 / área - 1,0)\n","*   concavidade (gravidade das porções côncavas do contorno)\n","*   pontos côncavos (número de porções côncavas do contorno)\n","*   simetria\n","*   dimensão fractal (\"aproximação do litoral\" - 1)\n","\n","Para cada característica foram extraídas a média, o erro padrão e o pior (ou maior) valor, resultando em 30 atributos para cada exame. A última coluna, 'diagnosis', contém a classe verdadeira de cada instância, que pode ser M (maligno) ou B (benigno).\n"," \n"],"metadata":{"id":"qNZC57moKTcG"}},{"cell_type":"markdown","source":["###Carregando e inspecionando os dados\n","\n","Além de possuir uma grande quantidade de algoritmos de aprendizado de máquina, a biblioteca [scikit-learn](https://scikit-learn.org/stable/index.html) possui também funções para carregar alguns conjuntos de dados. Neste notebook, vamos exemplificar o uso destas funções, fazendo o carregamento do dataset [Breast Cancer Wisconsin](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset). Este dataset é o mesmo utilizado na Aula 02, apenas mudaremos a forma de carregá-los no código."],"metadata":{"id":"owi-J_whK4IS"}},{"cell_type":"code","source":["import pandas as pd             # biblioteca para análise de dados \n","import matplotlib.pyplot as plt # biblioteca para visualização de informações\n","import seaborn as sns           # biblioteca para visualização de informações\n","import numpy as np              # biblioteca para operações com arrays multidimensionais\n","from sklearn.datasets import load_breast_cancer ## conjunto de dados a ser analisado\n","sns.set()\n","\n","data = load_breast_cancer() ## carrega os dados de breast cancer\n","X = data.data  # matriz contendo os atributos\n","y = data.target  # vetor contendo a classe (0 para maligno e 1 para benigno) de cada instância\n","feature_names = data.feature_names  # nome de cada atributo\n","target_names = data.target_names  # nome de cada classe\n","\n","print(f\"Dimensões de X: {X.shape}\\n\")\n","print(f\"Dimensões de y: {y.shape}\\n\")\n","print(f\"Nomes dos atributos: {feature_names}\\n\")\n","print(f\"Nomes das classes: {target_names}\")"],"metadata":{"id":"p-1VZTPjQax2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## transforma NumPy Array para Pandas DataFrame\n","data_df = pd.DataFrame(X,columns=feature_names)\n","\n","## sumariza os atributos numéricos (todos, neste caso)\n","data_df.describe()"],"metadata":{"id":"yFvDyhZ6isAw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Relembrando o número de exemplos por classe. Neste dataset carregado do scikit-learn, 0 representa maligno e 1 representa benigno (ao contrário do que usamos anteriormente)."],"metadata":{"id":"QEzW8LivnBDF"}},{"cell_type":"code","source":["n_malign = np.sum(y == 0)\n","n_benign = np.sum(y == 1)\n","\n","print(\"Número de exemplos malignos: %d\" % n_malign)\n","print(\"Número de exemplos benignos: %d\" % n_benign)"],"metadata":{"id":"SRHpI8VXSgZe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","---\n","\n","### Treinando uma árvore de decisão\n","\n","\n"],"metadata":{"id":"60j9N1m-gnf8"}},{"cell_type":"markdown","source":["Vamos iniciar a atividade treinando uma árvore de decisão seguindo o padrão do método DecisionTreeClassifier, sem especificar critérios de pré-poda ou pós-poda. Faremos uma divisão inicial dos dados em treino e teste para permitir a posterior avaliação do modelo.\n","\n","Todos os modelos deste notebook serão treinados utilizando o **critério Gini** para divisão de nós, que é o padrão adotado pelo scikit-learn."],"metadata":{"id":"DU4esGwnnYd8"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split  # função do scikit-learn que implementa um holdout\n","\n","## separa os dados em treino e teste, de forma estratificada\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y) ## atenção: não mude o random_state para este exercício\n","\n","## treina uma árvore de decisão com configurações 'padrão'\n","dtStd = DecisionTreeClassifier(random_state=0)\n","dtStd.fit(X_train, y_train)"],"metadata":{"id":"ZgdB4I3hnY3r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import graphviz\n","from sklearn import tree\n","\n","dot_data = tree.export_graphviz(dtStd,         \n","                                out_file=None,\n","                                feature_names = feature_names,\n","                                class_names= target_names, \n","                                filled=True)\n","\n","## Plotar a árvore de decisão no notebook\n","graph = graphviz.Source(dot_data) \n","graph\n","\n","## Para salvar como png, descomente as linhas abaixo\n","#graph.format = 'png'\n","#graph.render('DecisionTree1',view = True)\n"],"metadata":{"id":"ovxRuqTXpVAC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Responda >>>** *i)* Qual a profundidade da árvore treinada? *ii)* Qual parece ser o atributo mais informativo deste problema, de acordo com a árvore obtida?  "],"metadata":{"id":"7JcKAgKFsN0z"}},{"cell_type":"markdown","source":["> ***Sua resposta aqui:*** A árvore tem profundidade 8."],"metadata":{"id":"12QhL6s2sNPe"}},{"cell_type":"markdown","source":["**Responda >>>** Todos os 30 atributos disponíveis são testados na árvore? Em caso negativo, mencione quais foram avaliados pelo menos uma vez."],"metadata":{"id":"kpE2O6-3wFn1"}},{"cell_type":"markdown","source":["> ***Sua resposta aqui:*** Não. 14 atributos foram avaliados, sendo eles: 1) worst radius, 2) worst concave points, 3) texture error, 4) radius error, 5) worst texture, 6) worst concavity, 7) area error, 8) mean smoothness, 9) worst symmetry, 10) smoothness error, 11) worst area, 12) worst compactness, 13) worst perimeter, 14) ractal dimension error."],"metadata":{"id":"bDdHJG08wOYA"}},{"cell_type":"markdown","source":["**Responda >>>** Qual o menor e maior tamanho de amostras nos nós folhas desta árvore? Você acha que há sinais de *overfitting*?"],"metadata":{"id":"q9xfLRClaTJU"}},{"cell_type":"markdown","source":["> ***Sua resposta aqui:*** O menor nó folha tem tamanho 1, e o maior nó folha tem tamanho 236. Há sinais de overfitting no lado esquerdo da árvore."],"metadata":{"id":"ykmC3beeag9l"}},{"cell_type":"markdown","source":["####Avaliação do desempenho\n","Vamos avaliar o desempenho da árvore de decisão com os dados de teste. Para o cálculo de precisão e recall, assumimos a classe Tumor Maligno (0) como positiva."],"metadata":{"id":"FbkufVhCy6o4"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, recall_score, precision_score,accuracy_score,ConfusionMatrixDisplay ## para avaliação dos modelos\n","\n","y_pred = dtStd.predict(X_test)\n","\n","cm = confusion_matrix(y_test, y_pred,labels=dtStd.classes_)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dtStd.classes_)\n","disp = disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n","plt.grid(False)\n","plt.show()\n","\n","print('Acurácia: {}'.format(round(accuracy_score(y_test, y_pred),3)))\n","print('Recall: {}'.format(round(recall_score(y_test, y_pred,pos_label=0),3)))\n","print('Precisão: {}'.format(round(precision_score(y_test, y_pred,pos_label=0),3)))\n"],"metadata":{"id":"wq9msutRo6-y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Análise de instabilidade em árvores de decisão\n","Como estudado em aula, a árvore de decisão é conhecida por ser um classificador cuja fronteira de decisão é muito sensível a variações nos dados usados para treinamento. Assim, diz-se que árvores de decisão são modelos com alta variância. Isto possui consequências na estrutura das árvores treinadas.\n","\n","O código abaixo treina várias árvores de decisão com diferentes conjuntos de treino obtidos através do método 2-way holdout. Após conclusão da execução da célula de código, observe as árvores geradas. Os arquivos ficam armazenados na pasta 'content' do Google Colab.\n"],"metadata":{"id":"iMAD6e-vT5I6"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split  # função do scikit-learn que implementa um holdout\n","\n","\n","def get_root_node(dt, feature_names):\n","    feature_idx = dt.tree_.feature[0]\n","    return feature_names[feature_idx]\n","\n","\n","n_repeats = 10\n","root_nodes = []\n","\n","## variando o seed do holdout, geramos conjuntos de treino e teste um pouco diferentes a cada iteração\n","for split_random_state in range(0, n_repeats):\n","  ## Holdout com 20% de dados de teste\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=split_random_state,stratify=y)\n","\n","  ## Treinamento da árvore usando os dados de treino\n","  dt = DecisionTreeClassifier(random_state=0)\n","  dt.fit(X_train, y_train)\n","\n","  ## Obtemos o atributo usado na raiz e o salvamos na lista\n","  root_node = get_root_node(dt, feature_names)\n","  root_nodes.append(root_node)  \n","\n","  ## Opcionalmente, visualize a estrutura da árvore treinada:\n","  dot_data = tree.export_graphviz(dt,         \n","                                out_file=None,\n","                                feature_names = feature_names,\n","                                class_names= target_names, \n","                                filled=True)\n","\n","  ## Plotar a árvore de decisão no notebook\n","  graph = graphviz.Source(dot_data) \n","  graph\n","  \n","  ## Para salvar como png, descomente as linhas abaixo\n","  graph.format = 'png'\n","  graph.render('DecisionTree '+str(split_random_state),view = True)\n","\n","## Imprimindo atributos testados no nó raiz ao longo de todas as execuções.\n","root_nodes"],"metadata":{"id":"sWBWbbTIUuQc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Responda >>>** Analisando visualmente as árvores de decisão geradas, bem como o resumo dos atributos selecionados como nó raiz, você observou muitas variações entre as estruturas das árvores nas diferentes iterações? Relate de forma breve. Mencione na sua resposta se e como o atributo do nó raiz variou. Em caso de variação, cite os dois mais frequentes.\n","\n","\n"],"metadata":{"id":"y0EKlzPI1YeB"}},{"cell_type":"markdown","source":["> ***Sua resposta aqui:*** Sim, a estrutura das árvores variou muito, apesar das alturas serem parecidas. O atributo do nó raiz não teve tanta variação com 3 atributos, sendo os mais frequentes \"worst perimeter\" com 5 ocorrências e \"worst radius\" com 3 ocorrências."],"metadata":{"id":"2SYOeNsi192J"}},{"cell_type":"markdown","source":["####Avaliação do impacto no desempenho\n","É esperado que mudanças na estrutura da árvore causem variações no desempenho do modelo. Vamos avaliar esta hipótese, observando a acurácia como medida de desempenho (outras medidas poderiam ser usadas, você pode fazer alterações no código para testá-las)."],"metadata":{"id":"4dE3IWkdlpVP"}},{"cell_type":"markdown","source":["A célula de código abaixo visa executar repetidas vezes o treinamento das árvores de decisão, da mesma forma que no item anterior (entretanto, executa um número maior de vezes).\n","\n","Faça as inclusões sugeridas de forma a obter a acurácia do modelo em cada execução e então calcule a média, desvio padrão, máximo e mínimo dos valores. \n","**Não mude os valores que estão sendo passados para os parâmetros random_state**.\n","\n"],"metadata":{"id":"Dp5K0jyaLduN"}},{"cell_type":"markdown","source":["**Experimente >>>** Faça as adições solicitadas no código abaixo para calcular o que se pede."],"metadata":{"id":"Nq15qyUv6-n1"}},{"cell_type":"code","source":["n_repeats = 20\n","accuracies = [] ## para armazenar a lista de acurácia de todas as repetições\n","\n","## variando o seed do holdout, geramos conjuntos de treino e teste um pouco diferentes a cada iteração\n","for split_random_state in range(0, n_repeats):\n","  ## Holdout com 20% de dados de teste\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=split_random_state,stratify=y)\n","\n","  ## Treinamento da árvore usando os dados de treino\n","    ### \n","    # Adicione a sua resposta aqui\n","    ##\n","  dt = DecisionTreeClassifier(random_state=0)\n","  dt.fit(X_train, y_train)\n","\n","\n","  ##  Faça a predição da saída para os dados de teste e avalie a acurácia (accuracy_score())\n","    ### \n","    # Adicione a sua resposta aqui\n","    ##\n","  y_pred = dt.predict(X_test)\n","  #print('Acurácia: {}'.format(round(accuracy_score(y_test, y_pred),3)))\n","\n","\n","  ##Monte uma lista dos valores obtidos de acurácia (use \".append(valor a ser adicionado)\")\n","    ### \n","    # Adicione a sua resposta aqui\n","    ##\n","  accuracies.append(round(accuracy_score(y_test, y_pred),3))\n","\n","\n","## Ao final, calcule a média, desvio padrão, máximo e mínimo das acurácias \n","## (pode usar funções do numpy: np.mean, np.std, np.max, np.min)\n","  ### \n","  # Adicione a sua resposta aqui\n","  ##\n","print('Média: {}'.format(np.mean(accuracies)))\n","print('Min: {}'.format(np.min(accuracies)))\n","print('Max: {}'.format(np.max(accuracies)))\n","print('Desvio padrão: {}'.format(np.std(accuracies)))\n"],"metadata":{"id":"GGNDgUCzl2jV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Responda >>>** O desempenho do modelo de árvore de decisão sofreu alterações entre as múltiplas repetições? Reporte um resumo dos valores encontrados (por exemplo, valor máximo, mínimo e média)."],"metadata":{"id":"jU4t6nJT78up"}},{"cell_type":"markdown","source":["> ***Sua resposta aqui:*** Sim, variou com desvio padrão de 0.262 em torno da média 0.934.\n","\n","Média: 0.9342499999999999\n","\n","Min: 0.886\n","\n","Max: 0.974\n","\n","Desvio padrão: 0.026216168675075285"],"metadata":{"id":"npkslA8N8rX3"}},{"cell_type":"markdown","source":["####Avaliação do impacto na fronteira de decisão\n","Vamos observar a fronteira de decisão gerada para diferentes divisões de conjuntos de treino e teste, para averiguar o quanto a mesma pode ser impactada por variações nos dados. \n","\n","Para **fins de visualização**, assumimos como atributos preditivos apenas os **dois primeiros de X_train**. Além disso, aplicamos o algoritmo em um subconjunto dos dados para tornar a visualização mais clara."],"metadata":{"id":"QUZ-fGv35n2n"}},{"cell_type":"code","source":["## Função para plotar a fronteira de decisão\n","## Fonte: https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Utilities/ML-Python-utils.py\n","def plot_decision_boundaries(X, y, model_class, **model_params):\n","    \"\"\"\n","    Function to plot the decision boundaries of a classification model.\n","    This uses just the first two columns of the data for fitting \n","    the model as we need to find the predicted value for every point in \n","    scatter plot.\n","    Arguments:\n","            X: Feature data as a NumPy-type array.\n","            y: Label data as a NumPy-type array.\n","            model_class: A Scikit-learn ML estimator class \n","            e.g. GaussianNB (imported from sklearn.naive_bayes) or\n","            LogisticRegression (imported from sklearn.linear_model)\n","            **model_params: Model parameters to be passed on to the ML estimator\n","    \n","    Typical code example:\n","            plt.figure()\n","            plt.title(\"KNN decision boundary with neighbros: 5\",fontsize=16)\n","            plot_decision_boundaries(X_train,y_train,KNeighborsClassifier,n_neighbors=5)\n","            plt.show()\n","    \"\"\"\n","    try:\n","        X = np.array(X)\n","        y = np.array(y).flatten()\n","    except:\n","        print(\"Coercing input data to NumPy arrays failed\")\n","\n","    # Reduces to the first two columns of data - for a 2D plot!\n","    reduced_data = X[:, :2]\n","    # Instantiate the model object\n","    model = model_class(**model_params)\n","    # Fits the model with the reduced data\n","    model.fit(reduced_data, y)\n","\n","    # Step size of the mesh. Decrease to increase the quality of the VQ.\n","    h = .02     # point in the mesh [x_min, m_max]x[y_min, y_max].    \n","\n","    # Plot the decision boundary. For that, we will assign a color to each\n","    x_min, x_max = reduced_data[:, 0].min() - 0.5, reduced_data[:, 0].max() + 0.5\n","    y_min, y_max = reduced_data[:, 1].min() - 0.5, reduced_data[:, 1].max() + 0.5\n","    # Meshgrid creation\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n","\n","    # Obtain labels for each point in mesh using the model.\n","    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])    \n","\n","    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n","    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n","                         np.arange(y_min, y_max, 0.01))\n","\n","    # Predictions to obtain the classification results\n","    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n","\n","    # Plotting\n","    plt.contourf(xx, yy, Z, alpha=0.2,cmap='viridis')\n","    g=plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.6,s=50, edgecolor='k', cmap='viridis' )\n","    plt.xlabel(\"Feature-1\",fontsize=15)\n","    plt.ylabel(\"Feature-2\",fontsize=15)\n","    plt.xticks(fontsize=14)\n","    plt.yticks(fontsize=14)\n","    plt.legend(handles=g.legend_elements()[0],labels=('benign','malign'))\n","    return plt"],"metadata":{"id":"5zRzRCT7clsD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_repeats = 10\n","\n","for split_random_state in range(0, n_repeats):\n","  ## Holdout com 20% de dados de teste\n","  X_train, X_test, y_train, y_test = train_test_split(X[:,:2], y, test_size=0.2, random_state=split_random_state,stratify=y)\n","  \n","  plt.figure(figsize=(6, 4))\n","  ## chama a função para plotar a fronteira de decisão, a qual faz o treinamento\n","  ## do modelo com os dados informados\n","  plot_decision_boundaries(X_train[:50,:],y_train[:50],DecisionTreeClassifier, random_state=0)"],"metadata":{"id":"sNxw7QOGdKOn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Responda >>>** A análise das fronteira de decisão sugere a ocorrência de overfitting? Justifique"],"metadata":{"id":"v1XZn65XeEDU"}},{"cell_type":"markdown","source":["> ***Sua resposta aqui:*** Sim, além da área que delimita uma grande grupo, existem áreas menores, que parecem ter sido criados para classificar alguns  específicos."],"metadata":{"id":"32tWmunTeOWf"}},{"cell_type":"markdown","source":["#### Variação nos dados vs predição para instâncias individuais\n","\n","Para observar o quanto a variação nos dados pode impactar a predição para instâncias individuais, vamos fazer um último experimento. Execute o código abaixo e observe a saída do modelo para cada instância previamente selecionada (conforme definidas no código). As funções abaixo propositalmente não utilizam um random_state fixo."],"metadata":{"id":"OrsF5WMepURZ"}},{"cell_type":"markdown","source":["**Responda >>>** Informe as classes preditas pelo modelo para as cinco instâncias selecionadas neste [link](https://docs.google.com/spreadsheets/d/1QMOWestK5ZUCbsDDuBgBCxVCStW2qXMyydKnYkgftMM/edit?usp=sharing).\n","\n","\n"],"metadata":{"id":"u6gFQgZ6xsTK"}},{"cell_type":"code","source":["X_interesting = X[[40, 86, 297, 135, 73], :]\n","\n","## Instanciar uma nova árvore de decisão, dessa vez sem especificar o estado\n","dt = DecisionTreeClassifier()\n","\n","## Separar o conjunto em treino e teste, dessa vez sem especificar o estado\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y)\n","\n","## Treinar a nova árvore usando o conjunto de treino\n","dt.fit(X_train, y_train)\n","\n","## Usar a nova árvore treinada para obter predições para os valores de X acima.\n","y_pred = dt.predict(X_interesting)\n","print(y_pred)"],"metadata":{"id":"anY0STkIezLI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Estratégias de podas e seus efeitos"],"metadata":{"id":"AZelTK5blG_1"}},{"cell_type":"markdown","source":["As árvores de decisão treinadas nos itens anteriores não possuíam nenhuma forma de poda. Por padrão, a função disponibilizada pelo scikit-learn **não restringe o treinamento** das árvores.\n","\n","No entanto, é possível utilizar técnicas de poda através do scikit-learn. Vamos analisar duas estratégias conforme discutido em aula: pré-poda e pós-poda.\n","\n","Os exercícios abaixo visam demonstrar o efeito da poda na estrutura da árvore e na fronteira de decisão."],"metadata":{"id":"IYchPiY3lPMw"}},{"cell_type":"code","source":["## Separar o conjunto em treino e teste para os experimentos seguintes\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0,stratify=y)"],"metadata":{"id":"bdQZr4p8j2B3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Pré-poda: exemplos\n","Podemos especificar a profundidade máxima da árvore utilizando o hiperparâmetro `max_depth`. Iniciamos testando max_depth=2. Faça alterações no valor de `max_depth` para observar os resultados obtidos com diferentes profundidades máximas"],"metadata":{"id":"rKvCQYSjovEx"}},{"cell_type":"code","source":["dt = DecisionTreeClassifier(max_depth=4)\n","dt.fit(X_train, y_train)\n","\n","from sklearn.tree import plot_tree\n","plt.figure(figsize=(12,6))\n","_ = plot_tree(dt, feature_names=feature_names, class_names=target_names)"],"metadata":{"id":"8GyqN6H6jSYW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A célula de código abaixo analise o impacto de max_depth na fronteira de decisão. Novamente, simpĺificamos o conjunto de dados para fins de visualização: analisamos apenas dois atributos e um subconjunto de 50 instâncias."],"metadata":{"id":"nwNfBis8m83d"}},{"cell_type":"code","source":["fig, axs = plt.subplots(2, 2, figsize = (15, 10),sharey=True, sharex=True)\n","plt.sca(axs[0,0])\n","plot_decision_boundaries(X_train[:50,:],y_train[:50],DecisionTreeClassifier, random_state=0)\n","plt.title(\"Sem restrição\", fontsize=13)\n","plt.sca(axs[0,1])\n","plot_decision_boundaries(X_train[:50,:],y_train[:50],DecisionTreeClassifier, random_state=0,max_depth=3)\n","plt.title(\"max_depth=3\", fontsize=13)\n","plt.sca(axs[1,0])\n","plot_decision_boundaries(X_train[:50,:],y_train[:50],DecisionTreeClassifier, random_state=0,max_depth=2)\n","plt.title(\"max_depth=2\", fontsize=13)\n","plt.sca(axs[1,1])\n","plot_decision_boundaries(X_train[:50,:],y_train[:50],DecisionTreeClassifier, random_state=0,max_depth=1)\n","plt.title(\"max_depth=1\", fontsize=13)\n","plt.show()"],"metadata":{"id":"Gz3FeZ-akpdQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["O método [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) possui outros hiperparâmetros que podem ser ajustadas para um early *stopping* do treinamento da árvore de decisão: \n","\n","\n","*   `min_samples_leaf`: *The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.*\n","*   `min_samples_split`: *This may have the effect of smoothing the model, especially in regression.*\n","*   `max_leaf_nodes`: *Grow a tree with max_leaf_nodes in best-first fashion*\n","\n","\n","Vamos repetir a análise anterior, limitando o valor do hiperparâmetro `min_samples_leaf`. \n"],"metadata":{"id":"8ZDYHf11nylM"}},{"cell_type":"code","source":["#min_samples_leaf pode ser um valor inteiro ou um valor real: no segundo caso, é interpretado como uma proporção dos dados de treinamento\n","dt = DecisionTreeClassifier(min_samples_leaf=100,random_state=0) \n","dt.fit(X_train, y_train)\n","\n","from sklearn.tree import plot_tree\n","plt.figure(figsize=(12,6))\n","_ = plot_tree(dt, feature_names=feature_names, class_names=target_names)"],"metadata":{"id":"3f1ISCnRo4lA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, axs = plt.subplots(ncols=3, figsize = (15, 4),sharey=True, sharex=True)\n","plt.sca(axs[0])\n","plot_decision_boundaries(X_train[:50,:],y_train[:50],DecisionTreeClassifier, random_state=0)\n","plt.title(\"Sem restrição\", fontsize=13)\n","plt.sca(axs[1])\n","plot_decision_boundaries(X_train[:50,:],y_train[:50],DecisionTreeClassifier, random_state=0,min_samples_leaf=3)\n","plt.title(\"min_samples_leaf=3\", fontsize=13)\n","plt.sca(axs[2])\n","plot_decision_boundaries(X_train[:50,:],y_train[:50],DecisionTreeClassifier, random_state=0,min_samples_leaf=5)\n","plt.title(\"min_samples_leaf=5\", fontsize=13)\n","plt.show()"],"metadata":{"id":"auwQw1uoo4en"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Pós-poda: Custo-complexidade\n","\n","A biblioteca scikit-learn possui uma implementação de pós-poda por custo complexidade, baseada em custo-complexidade $\\alpha \\ge 0$.\n","\n","Na implementação descrita na biblioteca, é definido também um custo-complexidade efetivo do nodo. Quanto maior for a taxa de erros ao se podar a subárvore de um nodo, maior será seu custo-complexidade efetivo. Além disso, quanto maior for a complexidade (número de nodos terminais) da subárvore do nodo, menor será seu custo-complexidade efeito.\n","Em resumo, um nodo com alto custo-complexidade efetivo é um nodo importante para diminuir a taxa de erros e com baixa complexidade.\n","\n","Dentro da biblioteca, passamos um parâmetro $ccp\\_alpha$ que serve como um custo-complexidade efetivo de corte: subárvores são podadas enquanto houver nodos com custo-complexidade menor do que o parâmetro $ccp\\_alpha$.\n","Ou seja, quando maior for o parâmetro, mais intensa será a poda. \n","\n","Para mais informações:\n","* https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning\n","* https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html\n"],"metadata":{"id":"3IHz5Y-KvrCI"}},{"cell_type":"code","source":["dt = DecisionTreeClassifier(random_state=0, ccp_alpha=0.001)\n","dt.fit(X_train, y_train)\n","\n","from sklearn.tree import plot_tree\n","plt.figure(figsize=(12,6))\n","_ = plot_tree(dt, feature_names=feature_names, class_names=target_names)"],"metadata":{"id":"WApTmvqNsGnf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dt = DecisionTreeClassifier(random_state=0, ccp_alpha=0.05)\n","dt.fit(X_train, y_train)\n","\n","from sklearn.tree import plot_tree\n","plt.figure(figsize=(12,6))\n","_ = plot_tree(dt, feature_names=feature_names, class_names=target_names)"],"metadata":{"id":"LrfcYy_OsWsy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, axs = plt.subplots(ncols=2, figsize = (15, 4),sharey=True, sharex=True)\n","plt.sca(axs[0])\n","plot_decision_boundaries(X_train[:50,:],y_train[:50],DecisionTreeClassifier, random_state=0)\n","plt.title(\"Sem restrição\", fontsize=13)\n","plt.sca(axs[1])\n","plot_decision_boundaries(X_train[:50,:],y_train[:50],DecisionTreeClassifier, random_state=0,ccp_alpha=0.05)\n","plt.title(\"ccp_alpha=0.05\", fontsize=13)\n","plt.show()\n"],"metadata":{"id":"8iXEgGYqsisr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["O ajuste de `ccp_alpha`, bem como dos demais hiperparâmetros avaliados na pré-poda, não é algo trivial. Cada problema apresenta seu valor ótimo. No código abaixo vamos exemplificar como ajustar o valor de `ccp_alpha` para o problema em questão, testando diferentes possibilidades em um intervalo pré-definido.\n","\n","Opcionalmente, o scikit-learn fornece o método `cost_complexity_pruning_path` que ajuda a estima os valores de ccp_alpha mais efetivos, reduzindo o número de valores a serem testados. (Veja o código de exemplo ao final deste notebook)"],"metadata":{"id":"L0ryfsBrt-jQ"}},{"cell_type":"code","source":["## Definição da função para gerar um gráfico acurácia vs valores do hiperparâmetro\n","## hiperparâmetros escolhidos: \n","\n","def plot_acc_vs_hypervalues(accuracies_train, accuracies_test, hyper_values, hyper_name):\n","  fig, ax = plt.subplots(figsize=(12, 6))\n","  ax.set_xlabel(hyper_name)\n","  ax.set_ylabel(\"accuracy\")\n","  ax.set_title(\"Accuracy vs \" + hyper_name + \" for training and testing sets\")\n","  ax.plot(hyper_values, accuracies_train, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n","  ax.plot(hyper_values, accuracies_test, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n","  ax.legend()\n","  ax.grid()\n","  plt.show()\n","\n","## para armazenar desempenhos em treino e teste\n","accs_train = []\n","accs_test = []\n","\n","## definindo manualmente o intervalo de valores a ser testado para ccp\n","ccps = [k * 0.001 for k in range(0, 75, 3)]\n","\n","for ccp in ccps:\n","  dt = DecisionTreeClassifier(ccp_alpha=ccp, random_state=0)\n","  dt.fit(X_train, y_train)\n","  \n","  y_pred_train = dt.predict(X_train)\n","  acc_train = accuracy_score(y_train, y_pred_train)\n","\n","  y_pred_test = dt.predict(X_test)\n","  acc_test = accuracy_score(y_test, y_pred_test)\n","\n","  accs_train.append(acc_train)\n","  accs_test.append(acc_test)\n","\n","plot_acc_vs_hypervalues(accs_train, accs_test, hyper_values=ccps, hyper_name = \"alpha\")"],"metadata":{"id":"vHVEBHEG3Ugd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Responda >>>** De acordo com os resultados obtidos no gráfico acima, qual seria o melhor valor (ou melhores valores) de `ccp_alpha` a serem utilizados na poda da árvore para este conjunto de dados?"],"metadata":{"id":"0qweOd4Wv1T4"}},{"cell_type":"markdown","source":["> ***Sua resposta aqui:*** De acordo com o gráfico os valores de ccp_alpha entre 0.0 e 0.01 apresentaram os melhores resultados."],"metadata":{"id":"8dzqtM5BwGei"}},{"cell_type":"markdown","source":["---\n","\n","## Sua vez\n","\n","Seguindo o exemplo da otimização do valor do hiperparâmetro `ccp_alpha` para o treinamento de árvores de decisão para classificação do tipo de tumor, maligno ou benigno, faça a otimização de hiperparâmetros que controlam a liberdade de treinamento da árvore de decisão, isto é, que realizam **pré-poda**.\n","Varie os valores e avalie o efeito sobre o desempenho de pelo menos dois destes hiperparâmetros, conforme discutido na seção 'Pré-poda: exemplos'. \n","Apresente como resultados da sua atividade:\n","\n","\n","*   O gráfico que compara o desempenho vs o valor do hiperparâmetro para os dados de treino e teste.\n","*   A escolha do melhor valor de cada hiperparâmetro analisado, de acordo com os gráficos gerados.\n","*   A matriz de confusão para os dados de teste dos modelos gerados com os valores de hiperparâmetros otimizados neste exercício, comparando-os também a uma árvore de decisão treinada com pós-poda (escolha o valor de `ccp_alpha` de acordo com a otimização do hiperparâmetro feita neste notebook). Reporte acurácia, precisão e recall. \n","*   Qual abordagem foi melhor para treinar uma árvore de decisão que reduza os falsos negativos, isto é, maximize o recall?\n","\n","\n"],"metadata":{"id":"keCDKntOwQ9g"}},{"cell_type":"code","source":["## Solução SUA Vez\n","\n","## hiperparametro min_samples_leaf\n","accs_train = []\n","accs_test = []\n","min_samples_leafs = range(5, 30)\n","\n","for min_samples_leaf in min_samples_leafs:\n","  dt = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf, random_state=0)\n","  dt.fit(X_train, y_train)\n","  \n","  y_pred_train = dt.predict(X_train)\n","  acc_train = accuracy_score(y_train, y_pred_train)\n","\n","  y_pred_test = dt.predict(X_test)\n","  acc_test = accuracy_score(y_test, y_pred_test)\n","\n","  accs_train.append(acc_train)\n","  accs_test.append(acc_test)\n","\n","plot_acc_vs_hypervalues(accs_train, accs_test, hyper_values=min_samples_leafs, hyper_name = \"min samples leaf\")\n","\n","## hiperparametro max_leaf_node\n","accs_train = []\n","accs_test = []\n","max_leaf_nodes = range(5, 20)\n","\n","for max_leaf_node in max_leaf_nodes:\n","  dt = DecisionTreeClassifier(max_leaf_nodes=max_leaf_node, random_state=0)\n","  dt.fit(X_train, y_train)\n","  \n","  y_pred_train = dt.predict(X_train)\n","  acc_train = accuracy_score(y_train, y_pred_train)\n","\n","  y_pred_test = dt.predict(X_test)\n","  acc_test = accuracy_score(y_test, y_pred_test)\n","\n","  accs_train.append(acc_train)\n","  accs_test.append(acc_test)\n","\n","plot_acc_vs_hypervalues(accs_train, accs_test, hyper_values=max_leaf_nodes, hyper_name = \"max leaf node\")\n","\n","# escolhendo os melhores parametros pré\n","print('Visualizando melhores hiperparâmetro pré')\n","\n","x = 7 # min_samples_leaf\n","y = 15 # max_leaf_nodes \n","\n","dt_pre = DecisionTreeClassifier(min_samples_leaf=x, max_leaf_nodes=y, random_state=0)\n","dt_pre.fit(X_train, y_train)\n","y_pred_pre = dt_pre.predict(X_test)\n","\n","cm = confusion_matrix(y_test, y_pred_pre,labels=dt_pre.classes_)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dt_pre.classes_)\n","disp = disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n","plt.grid(False)\n","plt.show()\n","\n","print('Acurácia: {}'.format(round(accuracy_score(y_test, y_pred_pre),3)))\n","print('Recall: {}'.format(round(recall_score(y_test, y_pred_pre,pos_label=0),3)))\n","print('Precisão: {}'.format(round(precision_score(y_test, y_pred_pre,pos_label=0),3)))\n","\n","# escolhendo os melhores parametros pós\n","print('Visualizando melhores hiperparâmetro Pós')\n","dt_pos = DecisionTreeClassifier(ccp_alpha=0.005, random_state=0)\n","dt_pos.fit(X_train, y_train)\n","y_pred_pos = dt_pos.predict(X_test)\n","\n","cm = confusion_matrix(y_test, y_pred_pos,labels=dt_pos.classes_)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dt_pos.classes_)\n","disp = disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n","plt.grid(False)\n","plt.show()\n","\n","print('Acurácia: {}'.format(round(accuracy_score(y_test, y_pred_pos),3)))\n","print('Recall: {}'.format(round(recall_score(y_test, y_pred_pos,pos_label=0),3)))\n","print('Precisão: {}'.format(round(precision_score(y_test, y_pred_pos,pos_label=0),3)))\n","\n","# As duas abordagens apresentaram os mesmos melhores resultados para o recall, 0.952. \n"],"metadata":{"id":"BPO7Xpj6VfQB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","---\n","\n","\n","#### Sugestões de experimentos extras (opcionais):\n","\n","*   Expanda o seu estudo de pré-poda para os demais hiperparâmetros não explorados na atividade prática, fazendo a otimização dos seus valores. \n","*   Analise o efeito no desempenho no modelo ao utilizar o hiperparâmetro `class_weigths='balanced'` no método DecisionTreeClassifier. Esta configuração do hiperparâmetro atributo usa os valores de $y$ para ajustar automaticamente pesos inversamente proporcionais às frequências de classe nos dados de entrada, tentando reduzir o impacto do desbalanceamento entre classes.\n","*    Faça experimentos utilizando `criterion='entropy'` na escolha dos melhores atributos para divisão de nós da árvore. \n","*   Execute a otimização do hiperparâmetro `ccp_alpha` com os valores efetivos de `ccp_alpha` retornados pela função cost_complexity_pruning_path. Veja o exemplo utilizado na aula teórica [aqui](https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html). Os códigos com uso da função cost_complexity_pruning_path são fornecidos abaixo.\n","\n"],"metadata":{"id":"sROVD8fpwYzx"}},{"cell_type":"code","source":["## estima os valores de alpha efetivos e as respectivas impurezas.\n","clf = DecisionTreeClassifier(random_state=0)\n","path = clf.cost_complexity_pruning_path(X_train, y_train)\n","ccp_alphas, impurities = path.ccp_alphas, path.impurities"],"metadata":{"id":"-fQAZszHzl8Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Faz a análise visual da variação de impureza de acordo com o valor efetivo\n","fig, ax = plt.subplots()\n","ax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\")\n","ax.set_xlabel(\"effective alpha\")\n","ax.set_ylabel(\"total impurity of leaves\")\n","ax.set_title(\"Total Impurity vs effective alpha for training set\")"],"metadata":{"id":"sT-zCRmdzmRJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Treina diversas árvores de decisão, uma para cada valor efetivo de alpha\n","clfs = []\n","for ccp_alpha in ccp_alphas:\n","    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n","    clf.fit(X_train, y_train)\n","    clfs.append(clf)\n","print(\n","    \"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n","        clfs[-1].tree_.node_count, ccp_alphas[-1]\n","    )\n",")"],"metadata":{"id":"wqno3fHazx_4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Analisa a complexidade da árvore de acordo com a variação do valor efetivo de alpha\n","## Retira o último valor de alpha do array, pois representa a poda mais drástica, que deixa\n","## apenas o nó folha\n","clfs = clfs[:-1]\n","ccp_alphas = ccp_alphas[:-1]\n","\n","node_counts = [clf.tree_.node_count for clf in clfs]\n","depth = [clf.tree_.max_depth for clf in clfs]\n","fig, ax = plt.subplots(2, 1)\n","ax[0].plot(ccp_alphas, node_counts, marker=\"o\", drawstyle=\"steps-post\")\n","ax[0].set_xlabel(\"alpha\")\n","ax[0].set_ylabel(\"number of nodes\")\n","ax[0].set_title(\"Number of nodes vs alpha\")\n","ax[1].plot(ccp_alphas, depth, marker=\"o\", drawstyle=\"steps-post\")\n","ax[1].set_xlabel(\"alpha\")\n","ax[1].set_ylabel(\"depth of tree\")\n","ax[1].set_title(\"Depth vs alpha\")\n","fig.tight_layout()"],"metadata":{"id":"MbGqPvVqz_5y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Analisa a variação de desempenho para treino e teste.\n","train_scores = [clf.score(X_train, y_train) for clf in clfs]\n","test_scores = [clf.score(X_test, y_test) for clf in clfs]\n","\n","fig, ax = plt.subplots()\n","ax.set_xlabel(\"alpha\")\n","ax.set_ylabel(\"accuracy\")\n","ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n","ax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n","ax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n","ax.legend()\n","plt.show()"],"metadata":{"id":"UJ0Xrqf20NJq"},"execution_count":null,"outputs":[]}]}