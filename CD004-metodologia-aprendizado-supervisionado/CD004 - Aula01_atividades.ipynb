{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CD004 - Aula01_atividades.ipynb","provenance":[{"file_id":"1ESaSzqWJOv0dpqmxMXudUpDh2zUWcAUo","timestamp":1654865508998}],"collapsed_sections":[],"private_outputs":true,"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Especialização em Ciência de Dados - INF/UFRGS e SERPRO**\n","### Disciplina CD004 - Metodologia de Aprendizado de Máquina Supervisionado\n","#### *Profa. Mariana Recamonde-Mendoza (mrmendoza@inf.ufrgs.br)*\n","<br> \n","\n","---\n","***Observação:*** *Este notebook é disponibilizado aos alunos como complemento às aulas síncronas e aos slides preparados pela professora. Desta forma, os principais conceitos são apresentados no material teórico fornecido. O objetivo deste notebook é reforçar os conceitos e demonstrar questões práticas no uso de diferentes algoritmos e estratégias de Aprendizado de Máquina.*\n","\n","\n","---\n"],"metadata":{"id":"0FA12O8Tpjmk"}},{"cell_type":"markdown","source":["<br>\n","\n","## **Aula 01** - **Tópico: Avaliação de Modelos Preditivos**\n","\n","<br>\n","\n","Até o momento trabalhamos com a avaliação de modelos preditivos utilizando a estratégia mais simples, de **Holdout** - uma simples divisão aleatória dos dados em conjuntos de treinamento e teste (Holdout de 2 vias) ou em conjuntos de treinamento, validação e teste (Holdout de 3 vias). No entanto, um treinamento e avaliação robustos de modelos preditivos demanda o uso de outras estratégias de divisão de dados, especialmente quando estamos trabalhando com um conjunto de dados de tamanho limitado. Dentre estas estratégias, destacamos o *k-fold cross-validation*. \n","\n","O *k-fold cross-validation* (ou validação cruzada k-fold) e suas variantes (como *leave-one-out cross-validation* e *nested cross-validation*) estabeleceram-se como métodos referência para avaliar modelos em Aprendizado de Máquina pois mitigam diversas limitações relacionadas ao uso de Holdout, como i) permitir avaliar o desempenho de modelos preditivos com variações de conjuntos de dados de treinamento/teste (e assim evitar que os resultados dependam de uma escolha aleatória particular de divisão de dados), e ii) permitir que toda instância no conjunto de dados seja usada uma vez para avaliação do modelo.\n","\n","<br> \n","\n","**Objetivo deste notebook**: Explorar o uso de k-fold cross-validation para treinamento e avaliação de modelos preditivos, bem como aplicar diferentes métricas de desempenho para avaliação de modelos de classificação.\n","<br>\n","\n","---\n","\n"],"metadata":{"id":"VDNPuCNO2tpq"}},{"cell_type":"markdown","source":["\n","\n","##**Predição de risco de diabetes**\n","\n","Os dados que utilizaremos neste notebook foram coletados no artigo de [Islam et al (2019)](https://link.springer.com/chapter/10.1007/978-981-13-8798-2_12) com o propósito de desenvolver um modelo para auxiliar no diagnóstico precoce de diabetes. O diagnóstico precoce só é possível através da avaliação adequada dos sintomas comuns e menos comuns, que podem ser observados em diferentes fases desde o início da doença até o diagnóstico. Os autores geraram um conjunto de dados com 520 instâncias, que foi coletado usando questionários diretos dos pacientes do Sylhet Diabetes Hospital em Sylhet, Bangladesh. Para realização desta atividade, não consideraremos o atributo idade (já descartado no conjunto de dados a ser baixado). Todos os atributos são binários, com respostas Sim/Não (Yes/No)."],"metadata":{"id":"DbJNQfaM4ERT"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"jiutqCcGYYM0"}},{"cell_type":"markdown","source":["###Carregando e inspecionando os dados\n","\n","Primeiramente, vamos carregar algumas bibliotecas importantes do Python e os dados a serem utilizados neste estudo. Os dados são disponibilizados através de um link, que também pode ser diretamente acessado pelos alunos."],"metadata":{"id":"dbr-VwMq6OPG"}},{"cell_type":"code","source":["## Carregando as bibliotecas básicas necessárias\n","# A primeira linha é incluída para gerar os gráficos logo abaixo dos comandos de plot\n","%matplotlib inline              \n","import pandas as pd             # para análise de dados \n","import matplotlib.pyplot as plt # para visualização de informações\n","import seaborn as sns           # para visualização de informações\n","import numpy as np              # para operações com arrays multidimensionais\n","\n","## Bibliotecas para treinamento/avaliação de modelos\n","from sklearn.model_selection import RepeatedKFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score, cross_val_predict\n","from sklearn import metrics\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","## Bibliotecas para converter variáveis categóricas (strings) para numéricas\n","from sklearn.preprocessing import OrdinalEncoder \n","\n","sns.set()\n"],"metadata":{"id":"2lyNg5Sluhbg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Carregando os dados\n","df = pd.read_csv(\"https://drive.google.com/uc?export=view&id=1hSiFQPybmELwtIzbByASRxKp0TczCpn6\")\n","df  "],"metadata":{"id":"bPcnFsAB9kv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Características gerais do dataset\n","print(\"O conjunto de dados possui {} linhas e {} colunas\".format(df.shape[0], df.shape[1]))"],"metadata":{"id":"4BWj00iDltyH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Avalia se existem dados duplicados\n","## A presença de dados duplicados pode 'inflar' nossa estimativa de desempenho\n","df.drop_duplicates(keep='last').shape\n","df = df.drop_duplicates(keep='last')"],"metadata":{"id":"lFbe4X4cPwNf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Características gerais do dataset - após remoção de duplicatas\n","print(\"O conjunto de dados possui {} linhas e {} colunas\".format(df.shape[0], df.shape[1]))"],"metadata":{"id":"iCBVXyya-_tM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A coluna *'DiabetesRisk'* contém a classificação de cada instância. Vamos avaliar a distribuição de classes do problema."],"metadata":{"id":"UqoChZTpAEMu"}},{"cell_type":"code","source":["## Distribuição do atributo alvo\n","plt.hist(df['DiabetesRisk'])\n","plt.title(\"Distribuição do atributo alvo\")\n","plt.show()"],"metadata":{"id":"h0NT9TCiAeLX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['DiabetesRisk'].value_counts()"],"metadata":{"id":"QENNyVLMY77Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Podemos observar que neste conjunto de dados temos mais instâncias da classe 'DiabetesRisk' = 'Positive'. "],"metadata":{"id":"Ke0FQkjIYxgk"}},{"cell_type":"markdown","source":["Também é importante averiguar (ou confirmar) os tipos de dados de cada coluna (atributo), bem como se existem valores faltantes (que serão identificados pelo Python com o comando `isnull()`, portanto, caso estejam codificados de outra forma, é necessário substituir por NaN)."],"metadata":{"id":"9FfabKeQT8ja"}},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"yA30OBnnqPXf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Gerar um gráfico para cada variável categórica com a distribuição de \n","## frequência entre as classes\n","def count_plot(df,columns,label):\n","    plt.figure(figsize=(16, 10))\n","    for indx, var  in enumerate(columns):\n","        plt.subplot(4, 4, indx+1)\n","        g = sns.countplot(x=var, data=df, hue=label)\n","    plt.tight_layout()\n","\n","##Apenas as 15 primeiras colunas são atributos\n","count_plot(df,df.columns[:15],'DiabetesRisk') "],"metadata":{"id":"TDx387kzZTIC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","---\n","\n","\n","### Criando conjuntos de treino e teste para avaliação de modelos\n","\n","\n","Antes de iniciar o treinamento do modelo, lembre-se que é recomendado sempre reservar uma porção dos dados para teste, a qual somente será utilizada para avaliação do modelo final (após todo o processo de treinamento e otimização de hiperparâmetros).\n","\n","Vamos fazer esta divisão, separando 20% para teste. Entretanto, primeiro precisamos dividir os dados entre atributos (X) e classe (y). Também iremos codificar os valores categóricos em inteiros a fim de ampliar as opções de algoritmos que podemos utilizar no treinamento dos modelos.\n","\n"],"metadata":{"id":"63nQ-E0jVQzW"}},{"cell_type":"code","source":["## Separa o dataset em duas variáveis: os atributos/entradas (X) e a classe/saída (y)\n","X = df.drop(['DiabetesRisk'], axis=1)\n","y = df['DiabetesRisk'].values"],"metadata":{"id":"pd1ZSQRnXQq3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Codifica variáveis categóricas usando inteiros. \n","## Automaticamente detecta as categorias a partir dos dados. \n","## Neste caso, codifica Yes/No -> 1/0\n","encoder = OrdinalEncoder(dtype=np.int64)\n","encoder.fit(X)\n","X = encoder.transform(X)"],"metadata":{"id":"EzKRnMReaHMu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Imprime as 3 primeiras linhas após codificação, apenas para verificação\n","print(X[:3,:])"],"metadata":{"id":"kVck18WGXmt-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Faremos o mapeamento das classes Positive/Negative para 1/0. Por padrão, as funções de avaliação assumem que a classe 1 é a positiva/de interesse."],"metadata":{"id":"AfWwwt-QiB16"}},{"cell_type":"code","source":["## substitui 'Negative' por 0, 'Positive' por 1\n","y = np.array([0 if y=='Negative' else 1 for y in y]) "],"metadata":{"id":"vXM10ZIZjZzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Faz a divisão entre treino (80%) e teste (20%).\n","## O conjunto de treino representa os dados que serão usados\n","## ao longo do desenvolvimento do modelo\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,stratify=y,random_state=42) "],"metadata":{"id":"eZbsoLfsXkoZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","\n","### Treinamento de modelos com k-fold cross-validation\n","\n","O scikit-learn possui amplo suporte para uso de k-fold cross-validation. Existem duas funções no scikit-learn que você pode usar para realizar a validação cruzada, a função [`cross_val_score`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) e a função [`cross_validate`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html). A função `cross_val_score` está no scikit-learn há muito tempo e tem uma interface muito simples, enquanto a função `cross_validate` foi adicionada posteriormente, é um pouco mais poderosa e oferece mais opções (como especificar múltiplas métricas para avaliação). No entanto, ambas têm uma interface muito semelhante e são fáceis de usar. Uma questão importante é que elas permitem especificar tanto o algoritmo de aprendizado (estimator) como detalhes da divisão de dados (número de folds, [estratégia de divisão](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators), etc.) Por padrão, ambas usam 5-fold CV.\n","\n","O K-fold cross-validation (K-fold CV) visa de certa forma 'substituir' uma simples divisão entre treino/validação para o desenvolvimento dos modelos. Assim, vamos aplicar o k-Fold CV na partição `X_train` usando uma árvore de decisão e um KNN (por enquanto, sem otimização de hiperparâmetros). Preparamos o procedimento de k-Fold CV antes da função a fim de gerar a mesma partição de treino/teste para cada fold no caso de comparar múltiplos algoritmos. Usamos a versão `StratifiedKFold` para gerar uma divisão estratificada em relação às classes (para regressão, ou para problemas bem balanceados, podemos usar `KFold`)"],"metadata":{"id":"zuhzlay5bmQB"}},{"cell_type":"markdown","source":["#### Usando a função cross_val_score"],"metadata":{"id":"giHHh_qvwWKH"}},{"cell_type":"code","source":["cv_5f = StratifiedKFold(n_splits = 5, shuffle=True, random_state=42)\n","\n","## Avalia uma árvore de decisão com 5-fold CV\n","clf_dt = DecisionTreeClassifier(max_depth=5,class_weight='balanced',random_state=42)\n","scores_dt = cross_val_score(estimator=clf_dt, X=X_train, y=y_train,scoring='f1',cv=cv_5f) \n","\n","## Avalia um 5-NN com 5-fold CV\n","clf_knn = KNeighborsClassifier(n_neighbors=5)\n","scores_knn = cross_val_score(estimator=clf_knn, X=X_train, y=y_train,scoring='f1',cv=cv_5f) "],"metadata":{"id":"fKLCOjBlfLrS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(scores_dt)\n","print(np.mean(scores_dt))\n","print(np.std(scores_dt))"],"metadata":{"id":"Wgaz5Gjzj65t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(scores_knn)\n","print(np.mean(scores_knn))\n","print(np.std(scores_knn))"],"metadata":{"id":"56fzMJlMtn3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results=[]\n","results.append(scores_dt)\n","results.append(scores_knn)\n","plt.boxplot(results, labels=['DT','KNN'], showmeans=True)\n","plt.show()"],"metadata":{"id":"y-FHXNMYu3j2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A função [`cross_val_predict`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) tem uma interface similar a `cross_val_score`, mas retorna a predição de cada instância quando a mesma foi alocada ao conjunto de teste."],"metadata":{"id":"gvaPb3hMvZzL"}},{"cell_type":"code","source":["predict_dt = cross_val_predict(estimator=clf_dt, X=X_train, y=y_train,cv=cv_5f)#,method='predict_proba') ##descomente para retornar as probabilidades preditas\n","print(predict_dt)"],"metadata":{"id":"xfuJ80hqvt-g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Usando a função cross_validate"],"metadata":{"id":"mAAxDU1ZwdZs"}},{"cell_type":"markdown","source":["A função permite estabelecer um conjunto de métricas de avaliação no parâmetro [scoring](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter). \n","\n","Vamos utilizar para fins de exemplo, F1, Recall, Average Precision (sumariza a curva precisão-recall como a média ponderada das precisões obtidas em cada threshold the probabilidade), área sob a curva ROC e Acurácia."],"metadata":{"id":"7gFMnrinw4n_"}},{"cell_type":"code","source":["scoring = ['f1', 'recall','average_precision','roc_auc','accuracy']"],"metadata":{"id":"g6QMWaPvwcjt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Avalia uma árvore de decisão com 5-fold CV\n","scores_dt2 = cross_validate(estimator=clf_dt, X=X_train, y=y_train,scoring=scoring,cv=cv_5f) \n","\n","## Avalia um 5-NN com 5-fold CV\n","scores_knn2 = cross_validate(estimator=clf_knn, X=X_train, y=y_train,scoring=scoring,cv=cv_5f) "],"metadata":{"id":"8Mi2nOKqxpOe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores_dt2_df = pd.DataFrame(scores_dt2, columns=scores_dt2.keys()) \n","scores_dt2_df"],"metadata":{"id":"uIWWL6ylyAJk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.boxplot(scores_dt2_df[[\"test_f1\",\"test_recall\",\"test_average_precision\",\"test_roc_auc\",\"test_accuracy\"]].T,labels=['F1','Recall','AvgPrecision','ROC_AUC','Accuracy'],showmeans=True)\n","plt.show()"],"metadata":{"id":"P95lqbzE7sTq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores_knn2_df = pd.DataFrame(scores_knn2, columns=scores_dt2.keys()) \n","scores_knn2_df"],"metadata":{"id":"uJZAbm-AynA5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.boxplot(scores_knn2_df[[\"test_f1\",\"test_recall\",\"test_average_precision\",\"test_roc_auc\",\"test_accuracy\"]].T,labels=['F1','Recall','AvgPrecision','ROC_AUC','Accuracy'],showmeans=True)\n","plt.show()"],"metadata":{"id":"u8qENtxt8krh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Visualizando a divisão de dados com StratifiedKFold"],"metadata":{"id":"UcLFwmOp1lrg"}},{"cell_type":"markdown","source":["\n","Abaixo definimos uma funçao auxiliar para visualizar a divisão de dados feita pelo k-fold CV."],"metadata":{"id":"bHRQDR0Okdkq"}},{"cell_type":"code","source":["#Fonte: https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html\n","cmap_data = plt.cm.Paired\n","cmap_cv = plt.cm.coolwarm\n","\n","def plot_cv_indices(cv, X, y, ax, n_splits, lw=10):\n","    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n","\n","    # Generate the training/testing visualizations for each CV split\n","    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n","        # Fill in indices with the training/test \n","        indices = np.array([np.nan] * len(X))\n","        indices[tt] = 1\n","        indices[tr] = 0\n","\n","        # Visualize the results\n","        ax.scatter(\n","            range(len(indices)),\n","            [ii + 0.5] * len(indices),\n","            c=indices,\n","            marker=\"_\",\n","            lw=lw,\n","            cmap=cmap_cv,\n","            vmin=-0.2,\n","            vmax=1.2,\n","        )\n","\n","    # Plot the data classes and groups at the end\n","    ax.scatter(\n","        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data\n","    )\n","\n","    # Formatting\n","    yticklabels = list(range(n_splits)) + [\"class\"]\n","    ax.set(\n","        yticks=np.arange(n_splits + 1) + 0.5,\n","        yticklabels=yticklabels,\n","        xlabel=\"Sample index\",\n","        ylabel=\"CV iteration\",\n","        ylim=[n_splits + 2.2, -0.2],\n","        xlim=[0, 100],\n","    )\n","    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n","    return ax"],"metadata":{"id":"-L0Xl1p9kiHC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Na célula abaixo utilizamos a função `plot_cv_indices` para visualizar a distribuição das instâncias entre folds de treino e teste no 5-fold CV definido anteriormente."],"metadata":{"id":"an6b_-zW1sbu"}},{"cell_type":"code","source":["from matplotlib.patches import Patch\n","\n","fig, ax = plt.subplots()\n","plot_cv_indices(cv_5f, X_train, y_train, ax, n_splits=5)\n","ax.legend(\n","        [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n","        [\"Testing set\", \"Training set\"],\n","        loc=(1.02, 0.8),\n","    )"],"metadata":{"id":"jd70QllMzU1B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","### Treinamento de modelos com repeated k-fold cross-validation"],"metadata":{"id":"1TMJWSEH228s"}},{"cell_type":"markdown","source":["Podemos repetir o processo de k-fold CV múltiplas vezes utilizando a função `RepeatedKFold`. È possível perceber no gráfico abaixo que a cada repetição da divisão das instâncias em folds, obtemos uma \"configuração\" diferente. Na prática, passamos a ter a avaliação do modelo com 15 conjuntos de teste bem distintos. \n","\n","Entretanto, é importante perceber que separar os dados em 5 folds e repetir o processo 3 vezes é **diferente** de separar os dados em 15 folds e repetir o processo uma vez. No geral, dividir em menos folds e repetir o processo tantas vezes quantas forem possíveis é mais indicado, por permitir uma avaliação com uma maior variedade na distribuição dos dados."],"metadata":{"id":"pUxKGlGvfEja"}},{"cell_type":"code","source":["repcv_5f = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n"],"metadata":{"id":"um56Z9hX9TJD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots()\n","plot_cv_indices(repcv_5f, X_train, y_train, ax, n_splits=15)\n","ax.legend(\n","        [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n","        [\"Testing set\", \"Training set\"],\n","        loc=(1.02, 0.8),\n","    )"],"metadata":{"id":"TUqZ7LPn-B7s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cv_15f = StratifiedKFold(n_splits=15, shuffle=True,random_state=42)\n","\n","fig, ax = plt.subplots()\n","plot_cv_indices(cv_15f, X_train, y_train, ax, n_splits=15)\n","ax.legend(\n","        [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n","        [\"Testing set\", \"Training set\"],\n","        loc=(1.02, 0.8),\n","    )"],"metadata":{"id":"VE_h0H4XxFJQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Abaixo vamos realizar o treinamento dos dois modelos, baseado em árvores de decisão e baseado em KNN, utilizando o RepeatedKFold. O processo é exatamente igual ao que foi feito anteriormente, a diferença é que agora obtemos 15 estimativas de desempenho para cada modelo."],"metadata":{"id":"97EA4Zpyxh-S"}},{"cell_type":"code","source":["## Avalia uma árvore de decisão com 5-fold CV repetido 3 vezes\n","scores_dt_rep = cross_validate(estimator=clf_dt, X=X_train, y=y_train,scoring=scoring,cv=repcv_5f) \n","\n","## Avalia um 5-NN  com 5-fold CV repetido 3 vezes\n","scores_knn_rep = cross_validate(estimator=clf_knn, X=X_train, y=y_train,scoring=scoring,cv=repcv_5f) "],"metadata":{"id":"WOj_0vpI-wGb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores_dt2rep_df = pd.DataFrame(scores_dt_rep, columns=scores_dt_rep.keys()) \n","scores_dt2rep_df"],"metadata":{"id":"QluEETob936W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.boxplot(scores_dt2rep_df[[\"test_f1\",\"test_recall\",\"test_average_precision\",\"test_roc_auc\",\"test_accuracy\"]].T,labels=['F1','Recall','AvgPrecision','ROC_AUC','Accuracy'],showmeans=True)\n","plt.show()"],"metadata":{"id":"mn_PhW_C-guM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores_knn2rep_df = pd.DataFrame(scores_knn_rep, columns=scores_knn_rep.keys()) \n","scores_knn2rep_df"],"metadata":{"id":"b1sTmdIn-0tb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.boxplot(scores_knn2rep_df[[\"test_f1\",\"test_recall\",\"test_average_precision\",\"test_roc_auc\",\"test_accuracy\"]].T,labels=['F1','Recall','AvgPrecision','ROC_AUC','Accuracy'],showmeans=True)\n","plt.show()"],"metadata":{"id":"Q9KXW37T-_G0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Para avaliar o quanto os nossos modelos parecem promissores perto de um classificador 'dummy', sem nenhuma inteligência mas sim baseado em alguns critérios pré-definidos (como a classe majoritária), podemos utilizar a função `DummyClassifier`. Ela permite gerar um modelo 'baseline', que ignora os dados de entrada (atributos) e apenas olha a distribuição dos valores de saída nos dados de treinamento. A estratégia 'most_frequent' retorna sempre a classe mais frequente."],"metadata":{"id":"dYjbbcunA_2O"}},{"cell_type":"code","source":["from sklearn.dummy import DummyClassifier\n","clf_dummy = DummyClassifier(strategy='most_frequent', random_state=42)\n","scores_dummy_rep = cross_validate(estimator=clf_dummy, X=X_train, y=y_train,scoring=scoring,cv=repcv_5f) "],"metadata":{"id":"qR01--cYATdW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores_dummyrep_df = pd.DataFrame(scores_dummy_rep, columns=scores_dummy_rep.keys()) \n","scores_dummyrep_df"],"metadata":{"id":"CsqbwvYNAl08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(np.mean(scores_dt2rep_df))\n","print(np.mean(scores_knn2rep_df))\n","print(np.mean(scores_dummyrep_df))"],"metadata":{"id":"8T8OWZb2ym96"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pelo critério de F1-Score, o modelo de KNN (com k = 5) obteve os melhores resultados. Assim, este algoritmo poderia ser escolhido dentre os dois analisados (árvore de decisão e KNN) para treinar um modelo a partir de todos os dados de treinamento, e avaliar seu desempenho final nos dados de teste. Este desempenho final é a estimativa do poder preditivo que poderíamos obter caso este modelo seja aplicado para auxiliar no diagnóstico precoce de diabetes. "],"metadata":{"id":"AYRdH-ZdzQ1D"}},{"cell_type":"code","source":["#from sklearn.metrics import roc_curve, auc\n","knn_k5 = clf_knn.fit(X_train,y_train)\n","y_predProba_knn = knn_k5.predict_proba(X_test)\n","y_pred_knn = knn_k5.predict(X_test)\n","\n","print(metrics.accuracy_score(y_test,y_pred_knn))\n","print(metrics.f1_score(y_test,y_pred_knn))"],"metadata":{"id":"4zhAl7CspdSf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics.RocCurveDisplay.from_estimator(knn_k5, X_test, y_test)\n","\n","# alternativamente, a curva ROC pode ser gerada a partir das predições:\n","# fpr, tpr, thresholds = roc_curve(y_test,y_predProba_dt[:,1], pos_label=1)\n","# roc_auc = metrics.auc(fpr, tpr)\n","# display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,estimator_name='example estimator')\n","# display.plot()"],"metadata":{"id":"jzHu7m2IDT0M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualizando a curva de Precisão-Recall:"],"metadata":{"id":"iyGyyPIAtJpQ"}},{"cell_type":"code","source":["## Análise da curva PR\n","metrics.PrecisionRecallDisplay.from_estimator(knn_k5, X_test, y_test)"],"metadata":{"id":"gnJ_TZk_tKD2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","### Otimização de hiperparâmetros com GridSearch e Nested Cross-validation"],"metadata":{"id":"GhE3zGCb_OcM"}},{"cell_type":"markdown","source":["O sklearn disponibiliza a função `GridSearchCV`, que permite realizar a otimização de hiperparâmetros de forma prática usando k-fold cross-validation. Esta função já foi utilizada em exercícios anteriores da disciplina CD003, entretanto, na ocasião configuramos a função para utilizar splits de treino/validação pré-definidos. A chamada da função é muito simples:\n","\n","\n","\n","```\n","search = GridSearchCV(estimator, param_grid, scoring='f1', n_jobs=1, cv=5, refit=True)\n","```\n","\n","A função utiliza um modelo (`estimator`) para explorar as combinações de valores de hiperparâmetros definidos em `param_grid,` através de um 5-fold cross-validation (determinado por `cv`) e escolhe o melhor modelo a partir da métrica de F1-Score (também configurável). A opção `refit=True` define que após determinar a melhor configuração de hiperparâmetros, a mesma será utilizada para retreinar um modelo com todos os dados utilizados no processo de GridSearch com CV.\n","\n"],"metadata":{"id":"g0Xk_oDpgKqm"}},{"cell_type":"markdown","source":["A validação cruzada aninhada (nested cross-validation) é frequentemente usada para treinar um modelo no qual os hiperparâmetros também precisam ser otimizados. A seleção de modelo sem CV aninhado usa os mesmos dados para ajustar os hiperparâmetros do modelo e avaliar o desempenho do modelo. As informações podem, portanto, “vazar” para o modelo, que acaba se sobreajustando aos dados. O resultado deste vazamento pode ser uma avaliação excessivamente otimista. A magnitude desse efeito depende principalmente do tamanho do conjunto de dados e da estabilidade do modelo. \n","\n","Na célula abaixo, vamos executar o k-fold cross-validation e o nested cross-validation para os dados de risco de diabetes, treinando uma árvore de decisão com pré-pode. O hiperparâmetro a ser otimizado é o `max_depth`. Para os resultados mostrados abaixo, o desempenho refere-se sempre ao melhor valor de hiperparâmetro obtido a cada iteração do GridSearch."],"metadata":{"id":"Jqm0cQX2wSaV"}},{"cell_type":"code","source":["#Adaptado de: https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html\n","\n","from sklearn.model_selection import GridSearchCV\n","\n","# Número de execuções da validação cruzada (aninhada/não aninhada)\n","NUM_TRIALS = 30\n","\n","# Grid de hiperparâmetros para otimização\n","# param_grid = {\"max_depth\": [1,2,3,4,5,6,7]}\n","param_grid = {\"n_neighbors\": [1,3,5,7,9]}\n","\n","# Uso de uma árvore de decisão como algoritmo de aprendizado\n","# model = DecisionTreeClassifier()\n","model = KNeighborsClassifier()\n","\n","# Arrays para armazenar os scores de cada abordagem\n","non_nested_scores = np.zeros(NUM_TRIALS)\n","nested_scores = np.zeros(NUM_TRIALS)\n","\n","# Loop para múltiplas execuções, cada qual com um random_state distinto\n","for i in range(NUM_TRIALS):\n","\n","    # Definir estratégias de validação cruzada para o loop interno (inner) e para\n","    # o loop externo (outer). As escolhas podem ser diferentes. Aqui, optamos por\n","    # usar StratifiedKFold em ambas.\n","    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n","    outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n","\n","    # GridSearch e avaliação dos modelos na abordagem de k-fold cross-validation padrão\n","    # (sem aninhamento) - avalia os modelos com os mesmos dados usados para selecionar hiperparâmetros\n","    clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=outer_cv) ## sem aninhamento - desempenho com melhores hiperparâmetros\n","    clf.fit(X_train, y_train)\n","    non_nested_scores[i] = clf.best_score_\n","\n","    # GridSearch e avaliação dos modelos na abordagem de nested k-fold cross-validation\n","    clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=inner_cv, refit=True) ##inner CV - melhores hiperparâmetros\n","    nested_score = cross_val_score(clf, X=X_train, y=y_train, cv=outer_cv) ##outer CV - desempenho com melhores hiperparâmetros (do inner)\n","    nested_scores[i] = nested_score.mean()\n","\n","## Calcula a diferença de scores entre as abordagens\n","score_difference = non_nested_scores - nested_scores\n","\n","print(\n","    \"Average difference of {:6f} with std. dev. of {:6f}.\".format(\n","        score_difference.mean(), score_difference.std()\n","    )\n",")\n","\n","# Plotar um gráfico com os scores obtidos e com a diferença entre eles\n","# em cada iteração\n","plt.figure(figsize=(15,15))\n","plt.subplot(211)\n","(non_nested_scores_line,) = plt.plot(non_nested_scores, color=\"r\")\n","(nested_line,) = plt.plot(nested_scores, color=\"b\")\n","plt.ylabel(\"score\", fontsize=\"14\")\n","plt.legend(\n","    [non_nested_scores_line, nested_line],\n","    [\"Non-Nested CV\", \"Nested CV\"],\n","    bbox_to_anchor=(0, 0.4, 0.5, 0),\n",")\n","plt.title(\n","    \"Non-Nested and Nested Cross Validation on Diabetes Dataset\",\n","    x=0.5,\n","    y=1.1,\n","    fontsize=\"15\",\n",")\n","\n","# Plot bar chart of the difference.\n","plt.subplot(212)\n","difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n","plt.xlabel(\"Individual Trial #\")\n","plt.legend(\n","    [difference_plot],\n","    [\"Non-Nested CV - Nested CV Score\"],\n","    bbox_to_anchor=(0, 1, 0.8, 0),\n",")\n","plt.ylabel(\"score difference\", fontsize=\"14\")\n","\n","plt.show()"],"metadata":{"id":"KnDkK0q9w6v6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A célula a seguir faz a otimização de hiperparâmetros com nested cross-validation para o algoritmo KNN. O mesmo processo poderia ser adaptado ao algoritmo Árvores de Decisão ou outros que envolvam a busca por melhores hiperparâmetros."],"metadata":{"id":"SZGlkAb1do37"}},{"cell_type":"code","source":["# define o modelo\n","model = KNeighborsClassifier()\n","# define o espaço de busca de hiperparâmetros\n","param_grid = dict()\n","param_grid['n_neighbors'] = [1,3,5,7,9]\n","\n","### loop interno ####\n","# configura o loop interno do nested cross-validation\n","cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n","\n","# define a estratégia de busca dos melhores hiperparâmetros (baseado em F1)\n","search = GridSearchCV(model, param_grid, scoring='f1', n_jobs=1, cv=cv_inner, refit=True)\n","### loop interno ####\n","\n","### loop externo ####\n","# configura o loop externo do nested cross-validatiion\n","cv_outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","# executa o nested cross-validation\n","output_ncv = cross_validate(search, X_train, y_train, scoring=scoring, cv=cv_outer, n_jobs=-1,return_estimator=True, return_train_score=True)\n","### loop externo ####\n","\n","# reporta os resultados\n","pd.DataFrame(output_ncv)"],"metadata":{"id":"yEoq1FbXgPje"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Podemos avaliar os resultados do processo de nested cross-validation observando a variação de desempenho ao longo das múltiplas execuções e os melhores valores de hiperparâmetros selecionados em cada iteração. Cabe salientar que esta análise é feita com base no número de repetições do outer cross-validation (neste caso, configurado com 10 folds)"],"metadata":{"id":"ZYLpwXhXpZuQ"}},{"cell_type":"code","source":["# Análise de f1\n","mean_val_score = output_ncv['test_f1'].mean()\n","\n","print('nested_train_scores: ', output_ncv['train_f1'])\n","print('nested_val_scores:   ', output_ncv['test_f1'])\n","print('mean score:            {0:.2f}'.format(mean_val_score))"],"metadata":{"id":"_RuqlTwwbP4l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Análise de ROC AUC\n","mean_val_score = output_ncv['test_roc_auc'].mean()\n","\n","print('nested_train_scores: ', output_ncv['train_roc_auc'])\n","print('nested_val_scores:   ', output_ncv['test_roc_auc'])\n","print('mean score:            {0:.2f}'.format(mean_val_score))"],"metadata":{"id":"yjLzB0LGuMLO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Quais os melhores valores de hiperparâmetros de acordo com o nested Cross_validation?\n","[x.best_params_ for x in output_ncv['estimator']]"],"metadata":{"id":"bLD6dnSqbeoU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["O conhecimento a respeito dos melhores hiperparâmetros ao longo do nested cross-validation pode guiar nossa decisão sobre que modelos (algoritmos e configuração de hiperparâmetros) podemos utilizar para gerar o modelo final. Este modelo final seria obtido treinando um modelo com estas configurações sobre todo o conjunto de dados usado no processo de avaliação. \n","\n","A célula abaixo exemplifica este processo:"],"metadata":{"id":"jNjBQSnlpwlN"}},{"cell_type":"code","source":["## Treina o modelo com o valor \"ótimo\" do hiperparâmetro k\n","clf_knnOptimal = KNeighborsClassifier(n_neighbors=9)\n","clf_knnOptimal.fit(X_train, y_train)\n","\n","## Apĺica o modelo treinado para prever a saída dos dados de teste retidos no início da atividade\n","y_pred_knnOptimal = clf_knnOptimal.predict(X_test)\n","\n","## Análise da curva ROC\n","metrics.RocCurveDisplay.from_estimator(clf_knnOptimal, X_test, y_test)\n","\n","## Análise da curva PR\n","metrics.PrecisionRecallDisplay.from_estimator(clf_knnOptimal, X_test, y_test)\n"],"metadata":{"id":"Z5aEXqTrtSnI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(metrics.f1_score(y_test,y_pred_knnOptimal))"],"metadata":{"id":"qqWS8r-0t4yX"},"execution_count":null,"outputs":[]}]}