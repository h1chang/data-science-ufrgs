{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CD004 - Aula02_atividades.ipynb","provenance":[{"file_id":"1x8RNlYImrf9wnI_FDxu8UtZDQJkbgGyF","timestamp":1654865597385}],"collapsed_sections":[],"toc_visible":true,"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Especialização em Ciência de Dados - INF/UFRGS e SERPRO**\n","### Disciplina CD004 - Metodologia de Aprendizado de Máquina Supervisionado\n","#### *Profa. Mariana Recamonde-Mendoza (mrmendoza@inf.ufrgs.br)*\n","<br> \n","\n","---\n","***Observação:*** *Este notebook é disponibilizado aos alunos como complemento às aulas síncronas e aos slides preparados pela professora. Desta forma, os principais conceitos são apresentados no material teórico fornecido. O objetivo deste notebook é reforçar os conceitos e demonstrar questões práticas no uso de diferentes algoritmos e estratégias de Aprendizado de Máquina.*\n","\n","\n","---\n"],"metadata":{"id":"0FA12O8Tpjmk"}},{"cell_type":"markdown","source":["<br>\n","\n","## **Aula 02** - **Tópico: Comparação de Modelos Preditivos**\n","\n","<br>\n","\n","**Objetivo deste notebook**: Exemplificar o uso de intervalos de confiança e testes estatísticos para comparação de modelos preditivos.\n","<br>\n","\n","---\n","\n"],"metadata":{"id":"VDNPuCNO2tpq"}},{"cell_type":"markdown","source":["\n","\n","##**Predição de risco de diabetes**\n","\n","Os dados que utilizaremos neste notebook são os mesmos da Aula 01 e foram coletados no artigo de [Islam et al (2019)](https://link.springer.com/chapter/10.1007/978-981-13-8798-2_12) com o propósito de desenvolver um modelo para auxiliar no diagnóstico precoce de diabetes. O diagnóstico precoce só é possível através da avaliação adequada dos sintomas comuns e menos comuns, que podem ser observados em diferentes fases desde o início da doença até o diagnóstico. Os autores geraram um conjunto de dados com 520 instâncias, que foi coletado usando questionários diretos dos pacientes do Sylhet Diabetes Hospital em Sylhet, Bangladesh. Para realização desta atividade, não consideraremos o atributo idade (já descartado no conjunto de dados a ser baixado). Todos os atributos são binários, com respostas Sim/Não (Yes/No)."],"metadata":{"id":"DbJNQfaM4ERT"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"jiutqCcGYYM0"}},{"cell_type":"markdown","source":["###Carregando e inspecionando os dados\n","\n","Primeiramente, vamos carregar algumas bibliotecas importantes do Python e os dados a serem utilizados neste estudo. Os dados são disponibilizados através de um link, que também pode ser diretamente acessado pelos alunos."],"metadata":{"id":"dbr-VwMq6OPG"}},{"cell_type":"code","source":["## Carregando as bibliotecas básicas necessárias\n","# A primeira linha é incluída para gerar os gráficos logo abaixo dos comandos de plot\n","%matplotlib inline              \n","import pandas as pd             # para análise de dados \n","import matplotlib.pyplot as plt # para visualização de informações\n","import seaborn as sns           # para visualização de informações\n","import numpy as np              # para operações com arrays multidimensionais\n","\n","## Bibliotecas para treinamento/avaliação de modelos\n","from sklearn.model_selection import RepeatedKFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score, cross_val_predict, GridSearchCV\n","from sklearn import metrics\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","## Bibliotecas para converter variáveis categóricas (strings) para numéricas\n","from sklearn.preprocessing import OrdinalEncoder \n","\n","sns.set()\n"],"metadata":{"id":"2lyNg5Sluhbg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Carregando os dados\n","df = pd.read_csv(\"https://drive.google.com/uc?export=view&id=1hSiFQPybmELwtIzbByASRxKp0TczCpn6\")\n","df  "],"metadata":{"id":"bPcnFsAB9kv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Características gerais do dataset\n","print(\"O conjunto de dados possui {} linhas e {} colunas\".format(df.shape[0], df.shape[1]))"],"metadata":{"id":"4BWj00iDltyH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Remoção dos dados duplicados\n","df.drop_duplicates(keep='last').shape\n","df = df.drop_duplicates(keep='last')"],"metadata":{"id":"lFbe4X4cPwNf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A coluna *'DiabetesRisk'* contém a classificação de cada instância. Vamos avaliar a distribuição de classes do problema."],"metadata":{"id":"UqoChZTpAEMu"}},{"cell_type":"code","source":["## Distribuição do atributo alvo\n","plt.hist(df['DiabetesRisk'])\n","plt.title(\"Distribuição do atributo alvo\")\n","plt.show()"],"metadata":{"id":"h0NT9TCiAeLX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['DiabetesRisk'].value_counts()"],"metadata":{"id":"QENNyVLMY77Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","---\n","\n","\n","### Criando conjuntos de treino e teste para avaliação de modelos\n","\n","\n","Antes de iniciar o treinamento do modelo, lembre-se que é recomendado sempre reservar uma porção dos dados para teste, a qual somente será utilizada para avaliação do modelo final (após todo o processo de treinamento e otimização de hiperparâmetros).\n","\n","Vamos fazer esta divisão, separando 20% para teste. Entretanto, primeiro precisamos dividir os dados entre atributos (X) e classe (y). Também iremos codificar os valores categóricos em inteiros a fim de ampliar as opções de algoritmos que podemos utilizar no treinamento dos modelos.\n","\n"],"metadata":{"id":"63nQ-E0jVQzW"}},{"cell_type":"code","source":["## Separa o dataset em duas variáveis: os atributos/entradas (X) e a classe/saída (y)\n","X = df.drop(['DiabetesRisk'], axis=1)\n","y = df['DiabetesRisk'].values"],"metadata":{"id":"pd1ZSQRnXQq3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Codifica variáveis categóricas usando inteiros. \n","## Automaticamente detecta as categorias a partir dos dados. \n","## Neste caso, codifica Yes/No -> 1/0\n","encoder = OrdinalEncoder(dtype=np.int64)\n","encoder.fit(X)\n","X = encoder.transform(X)"],"metadata":{"id":"EzKRnMReaHMu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Faremos o mapeamento das classes Positive/Negative para 1/0. Por padrão, as funções de avaliação assumem que a classe 1 é a positiva/de interesse."],"metadata":{"id":"AfWwwt-QiB16"}},{"cell_type":"code","source":["## substitui 'Negative' por 0, 'Positive' por 1\n","y = np.array([0 if y=='Negative' else 1 for y in y]) "],"metadata":{"id":"vXM10ZIZjZzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Faz a divisão entre treino (80%) e teste (20%).\n","## O conjunto de treino representa os dados que serão usados\n","## ao longo do desenvolvimento do modelo\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,stratify=y,random_state=42) "],"metadata":{"id":"eZbsoLfsXkoZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","\n","## Comparação de modelos com intervalos de confiança\n","\n","Para gerar intervalos de confiança para uma determinada métrica e diferentes modelos de aprendizado supervisionado, vamos utilizar a estratégia de bootstrap. A construção dos intervalos de confiança é realizada conforme o que foi estudado em aula:\n","\n","\n","*   B amostras de bootstrap aleatórias são geradas, \n","*   uma estimativa de desempenho é calculada a partir de cada amostra de bootstrap, \n","*   todas as estimativas de desempenho de bootstrap B são ordenadas do valor mais baixo para o mais alto, \n","*   o intervalo de confiança é construído selecionando os limites  [Percentil 100 x (α/2), Percentil 100 x (1 - α/2) ], para α = 0.05 (confiança de 95%) a partir da distribuição gerada\n","\n","É importante notar que o procedimento acima é realizado para uma avaliação mais robusta de desempenho do modelo. No caso de ser feito otimização de hiperparâmetros, o processo pode estar dentro do loop dos boostraps, ou ainda, o processo de boostrap pode ser usado com diferentes configurações de hiperparâmetros."],"metadata":{"id":"ZkOKOBleLW0b"}},{"cell_type":"code","source":["from sklearn.utils import resample\n","\n","## configura o bootstrap. Serão realizadas 1000 iterações com reposição.\n","## as instâncias amostradas serão usadas para treino \n","n_iterations = 1000\n","n_size = int(len(X_train))"],"metadata":{"id":"NcoRf69fL-06"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## executa o bootstrap\n","stats_dt = list()\n","stats_knn = list()\n","\n","for i in range(n_iterations):\n","\t# prepara treino e validação do bootstrap. as instâncias amostradas vão para partição de treino,\n","\t# e as demais para a de validação (out-of-bag)deste bootstrap \n","\ttrain = resample(X_train, n_samples=n_size,random_state=i,replace=True)\n","\tvalid = np.array([x for x in X_train if x.tolist() not in train.tolist()])\n"," \n","\t#treina o modelo de DT\n","\tmodel_dt = DecisionTreeClassifier(max_depth=5, class_weight='balanced',random_state=42)\n","\tmodel_dt.fit(train[:,:-1], train[:,-1])\n"," \n","\t# avalia o modelo de DT\n","\tpredictions_dt = model_dt.predict(valid[:,:-1])\n","\tscore_dt = metrics.accuracy_score(valid[:,-1], predictions_dt)\n","\tstats_dt.append(score_dt)\n"," \n"," \t#treina o modelo de KNN\n","\tmodel_knn = KNeighborsClassifier(n_neighbors=5)\n","\tmodel_knn.fit(train[:,:-1], train[:,-1])\n","\n","\t# avalia o modelo de KNN\n","\tpredictions_knn = model_knn.predict(valid[:,:-1])\n","\tscore_knn = metrics.accuracy_score(valid[:,-1], predictions_knn)\n","\tstats_knn.append(score_knn)"],"metadata":{"id":"M3ifW-h6L3ZV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plota histograma dos scores\n","plt.figure(figsize=(10,7))\n","plt.subplot(211)\n","plt.hist(stats_dt)\n","plt.title(\"Distribuição de desempenho para árvore de decisão\")\n","\n","\n","plt.subplot(212)\n","plt.hist(stats_knn)\n","plt.title(\"Distribuição de desempenho para KNN\")\n","\n","plt.show()"],"metadata":{"id":"-39ARC4ZL9YV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Intervalos de confiança. Nível de confiança dado por alpha\n","alpha = 0.95\n","\n","## Árvore de Decisão\n","p = ((1.0-alpha)/2.0) * 100\n","lower = max(0.0, np.percentile(stats_dt, p))\n","p = (alpha+((1.0-alpha)/2.0)) * 100\n","upper = min(1.0, np.percentile(stats_dt, p))\n","print('Árvore de decisão. Média: %.1f' % np.mean(stats_dt))\n","print('%.1f confidence interval %.1f%% and %.1f%%' % (alpha*100, lower*100, upper*100))\n","\n","\n","## KNN\n","p = ((1.0-alpha)/2.0) * 100\n","lower = max(0.0, np.percentile(stats_knn, p))\n","p = (alpha+((1.0-alpha)/2.0)) * 100\n","upper = min(1.0, np.percentile(stats_knn, p))\n","print('KNN. Média: %.1f' % np.mean(stats_knn))\n","print('%.1f confidence interval %.1f%% and %.1f%%' % (alpha*100, lower*100, upper*100))"],"metadata":{"id":"J2ar09fOL6_h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","\n","## Comparação de modelos com teste de hipótese\n","\n","Vamos utilizar os métodos implementados na biblioteca do Python [mlxtend](http://rasbt.github.io/mlxtend/) (machine learning extesions) para fazer uma comparação estatística de modelos usando testes de hipótese. A bilbioteca disponibiliza os testes estudados em aula: teste de McNemar e teste t de sutdent com 5x2 CV para comparar dois classificadores, teste Q de Cochran para comparar múltiplos classificadores. Abaixo vamos exemplificar o uso de cada um deles. "],"metadata":{"id":"zuhzlay5bmQB"}},{"cell_type":"markdown","source":["Iniciamos instalando a biblioteca."],"metadata":{"id":"grd9W9B4s7wy"}},{"cell_type":"code","source":["!pip install mlxtend "],"metadata":{"id":"XyGFMEwIsVyU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","#### Comparação entre dois classificadores"],"metadata":{"id":"giHHh_qvwWKH"}},{"cell_type":"markdown","source":["Esta seção exemplifica o uso do Teste t pareado modificado para combinar dois classificadores. Utilizaremos o método [paired_ttest_5x2cv](http://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_5x2cv/)."],"metadata":{"id":"Mkxzhxk0M6r4"}},{"cell_type":"code","source":["from mlxtend.evaluate import paired_ttest_5x2cv\n","\n","clf1 = KNeighborsClassifier(n_neighbors=1)\n","clf2 = DecisionTreeClassifier(random_state=42,max_depth=4)\n","\n","t, p = paired_ttest_5x2cv(estimator1=clf1,\n","                          estimator2=clf2,\n","                          X=X, y=y,\n","                          random_seed=1,\n","                          scoring='f1')\n"],"metadata":{"id":"ImK6MAprtO_G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sumarizando\n","print('P-valor: %.3f, t-Statistic: %.3f' % (p, t))\n","# interpretando o resultado\n","if p <= 0.05:\n","\tprint('Diferença no desempenho médio provavelmente é real (significativa)')\n","else:\n","\tprint('Os algoritmos provavelmente possuem o mesmo desempenho médio')"],"metadata":{"id":"9W4Za-eixuMJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Este notebook se concentra em exemplificar o uso dos testes de hipótese no contexto de aprendizado de máquina. Antes de iniciar a comparação estatística, poderíamos ter realizado uma otimização de hiperparâmetros para entender o desempenho dos algoritmos em diferentes configurações, escolhendo a melhor. A análise estatística é comumente usada para avaliar o desempenho final dos modelos. Para fins de simplificação, esta etapa não foi executada neste notebook."],"metadata":{"id":"5eQ82cjBNUnC"}},{"cell_type":"markdown","source":["#### Comparação entre múltiplos classificadores"],"metadata":{"id":"pUB36MgfTIlw"}},{"cell_type":"markdown","source":["A comparação entre múltiplos modelos pode ser feita com o teste de Cochrans. A biblioteca mlxtend disponibiliza uma implementação do método, [veja neste link](http://rasbt.github.io/mlxtend/user_guide/evaluate/cochrans_q/)"],"metadata":{"id":"l2ALt0LvXLWv"}},{"cell_type":"code","source":["from mlxtend.evaluate import cochrans_q\n","from mlxtend.evaluate import mcnemar_table\n","from mlxtend.evaluate import mcnemar\n","from sklearn.svm import SVC\n","\n","clf1 = KNeighborsClassifier(n_neighbors=9)\n","clf1.fit(X_train,y_train)\n","y_clf1 = clf1.predict(X_test)\n","\n","clf2 = DecisionTreeClassifier(random_state=42,max_depth=4)\n","clf2.fit(X_train,y_train)\n","y_clf2 = clf2.predict(X_test)\n","\n","clf3 = SVC(kernel='rbf',C=0.1,class_weight='balanced')\n","clf3.fit(X_train,y_train)\n","y_clf3 = clf3.predict(X_test)\n","\n","q, p_value = cochrans_q(y_test, \n","                        y_clf1, \n","                        y_clf2, \n","                        y_clf3)\n","\n","# sumarizando\n","print('P-valor: %.3f, Q: %.3f' % (p_value, q))\n","# interpretando o resultado\n","if p_value <= 0.05:\n","\tprint('Diferença no desempenho médio provavelmente é real (significativa)')\n","else:\n","\tprint('Os algoritmos provavelmente possuem o mesmo desempenho médio')"],"metadata":{"id":"ziM3Zp7TTdEW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Caso o teste de Cochrans entre os múltiplos modelos retorne um p-valor significativo, precisamos fazer testes pos-hoc par-a-par para investigar quais modelos diferem significativamente entre si em termos de desempenho preditivo. Uma possibilidade de teste a ser aplicado nesta estapa é o McNemar, indicado para comparação entre dois modelos."],"metadata":{"id":"wO5LwxPMPmXY"}},{"cell_type":"code","source":["chi2, p_value = mcnemar(mcnemar_table(y_test, \n","                                      y_clf1, \n","                                      y_clf2),\n","                        corrected=False)\n","\n","print('KNN vs DT. McNemar\\'s Chi^2: %.3f' % chi2)\n","print('KNN vs DT. McNemar\\'s p-value: %.3f' % p_value)\n","\n","\n","chi2, p_value = mcnemar(mcnemar_table(y_test, \n","                                      y_clf1, \n","                                      y_clf3),\n","                        corrected=False)\n","\n","print('KNN vs SVC. McNemar\\'s Chi^2: %.3f' % chi2)\n","print('KNN vs SVC. McNemar\\'s p-value: %.3f' % p_value)\n","\n","chi2, p_value = mcnemar(mcnemar_table(y_test, \n","                                      y_clf2, \n","                                      y_clf3),\n","                        corrected=False)\n","\n","print('DT vs SVC. McNemar\\'s Chi^2: %.3f' % chi2)\n","print('DT vs SVC. McNemar\\'s p-value: %.3f' % p_value)"],"metadata":{"id":"zqMH_Ps8VCxS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Enquanto este notebook se propôs a introduzir alguns testes estatísticos, a biblioteca mlxtend possui diversos outros métodos disponíveis para comparação de modelos em Aprendizado de Máquina. Veja a d[ocumentação](http://rasbt.github.io/mlxtend/#) da biblioteca e os exemplos de aplicação dos demais testes de hipótese."],"metadata":{"id":"WN2ByG40ZWLl"}}]}